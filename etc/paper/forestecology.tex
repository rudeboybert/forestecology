% !TeX program = pdfLaTeX
\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
\usepackage{natbib}
\usepackage{textcomp}
\usepackage[hyphens]{url} % not crucial - just used below for the URL
\usepackage{hyperref}
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%

%% load any required packages here


\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}

% Pandoc citation processing

\usepackage{xcolor, soul, xspace, float, subfig, lineno}

\begin{document}


\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\if0\blind
{
  \title{\bf The \texttt{forestecology} R package for modeling interspecies
competition between trees}

  \author{
        Albert Y. Kim \thanks{Albert Y. Kim is Assistant Professor, Statistical \& Data Sciences,
Smith College, Northampton, MA 01063 (e-mail:
\href{mailto:akim04@smith.edu}{\nolinkurl{akim04@smith.edu}}).} \\
    Program in Statistical \& Data Sciences, Smith College\\
     and \\     David Allen \\
    Biology Department, Middlebury College\\
     and \\     Simon P. Couch \\
    Mathematics Department, Reed College\\
      }
  \maketitle
} \fi

\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf The \texttt{forestecology} R package for modeling interspecies
competition between trees}
  \end{center}
  \medskip
} \fi

\bigskip
\begin{abstract}
Move abstract below here after completed.
\end{abstract}

\noindent%
{\it Keywords:} forest ecology, competition, R, Rstats, tidyverse, sf, cross-validation,
\vfill

\newpage
\spacingset{1.45} % DON'T change the spacing!

\linenumbers

\hypertarget{abstract-350-words}{%
\section*{Abstract (350 words)}\label{abstract-350-words}}
\addcontentsline{toc}{section}{Abstract (350 words)}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  When modeling growth of trees forest ecologists often incorporate the
  effect of interspecies competition. Many such models are based on a
  neighborhood effect assumption whereby all trees within a fixed
  distance of all focal trees are considered competitors. Methods are
  needed to evaluate the effect of interspecies competition and to
  assess their quality.
\item
  We present the \texttt{forestecology} package providing methods for
  both 1) evaluating the out-of-sample performance of our model using
  spatial-crossvaliation and 2) testing a null hypothesis of of no
  impact of competitor species' identity on the growth of trees using a
  permutation test. We implement a class and methods using R's S3
  object-oriented system, for a specific linear, Bayesian neighborhood
  competition model of tree growth.
\item
  We demonstrate the package's functions using data from the Smithsonian
  Conservation Biology Institute's large forest dynamics plot, part of
  the ForestGEO network of reseach sites. Given ForestGEO's data
  collection protocols and data formatting standards, the package
  cross-compatibility of code. We show both that 1) competitor species
  identity matters and 2) that not spatially cross-validating leads to
  error estimates that are overly optimistic.
\item
  The package follows \texttt{tidyverse}-like structure whereby
  verb-named functions can be modularly ``piped'' in sequence to
  intuitively display the sequence of steps of analysis from start to
  finish. Additionally, most inputs/outputs of functions assume an are
  of \texttt{sf} class from the simple features package, thereby
  facilitating all wrangling and visualization of geospatial data.
  Lastly, even though our package is currently limited to one specific
  model, the package is setup such that it can be easily extended to
  other models.
\end{enumerate}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Repeat-censused forest plots offer excellent data to test neighborhood
models of tree competition \citet{allen_permutation_2020}
\citet{canham_neighborhood_2006} \citet{uriarte_spatially_2004}. Here we
describe an R package, \texttt{forestecology}, to do that. This package
implements the methods in \citet{allen_permutation_2020}. It provides: a
convenient way to specify and fit models of tree growth based on
neighborhood competition; a spatial cross validation method to test and
compare model fits \citet{roberts_cross-validation_2017}; and an
ANOVA-like method to assess whether the competitor identity matters in
these models. The model is written to work with ForestGEO plot data
\citet{andersonteixeira_ctfs-forestgeo_2015}, but we envision that it
could easily be modified to work with data from other forest plots,
e.g.~the US Forest Service Forest Inventory and Analysis plots
\citet{smith_forest_2002}.

The \texttt{forestecology} is designed with ``tidy'' data principles in
mind as \citet{wickham_welcome_2019}.

Given that our data is of geo-spatial nature, we represent our data
using the ``simple features'' \texttt{sf} package class of objects
\citet{pebesma_simple_2018} whereby. While previously the \texttt{sp}
package serves such purposes \citet{pebesma_sp_2005}, the \texttt{sf}
package is designed to interface with the \texttt{tidyverse} suite of
packages.

\hypertarget{example}{%
\section{Example}\label{example}}

We demonstrate the \texttt{forestecology} package's features on the
Smithsonian Conservation Biology Institute (SCBI) large forest dynamics
plot, located at the Smithsonian's National Zoo and Conservation Biology
Institute in Front Royal, VA, USA. The 25.6 ha (640 x 400 m) plot is
located at the intersection of three of the major physiographic
provinces of the eastern US: the Blue Ridge, Ridge and Valley, and
Piedmont provinces and is adjacent to the northern end of Shenandoah
National Park. The forest type is typical mature secondary eastern mixed
deciduous forest, with a canopy dominated by tulip poplar
(\emph{Liriodendron tulipifera}), oaks (\emph{Quercus} spp.), and
hickories (\emph{Carya} spp.), and an understory composed mainly of
spicebush (\emph{Lindera benzoin}), paw-paw (\emph{Asimina triloba}),
American hornbeam (\emph{Carpinus caroliniana}), and witch hazel
(\emph{Hamamelis virginiana}) \citet{bourg_initial_2013}.

A high-level overview of the steps of our analysis pipeline is as
follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute the growth of trees based on census data
\item
  Add spatial information:

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    Define buffer region trees.
  \item
    Add spatial cross-validation block information.
  \end{enumerate}
\item
  Compute focal versus competitor tree information.
\item
  Fit model and make predictions.
\item
  Visualize model results.
\item
  Additionally: Evaluate model performance using spatial
  cross-validation.
\item
  Additionally: Evaluate the effect of competitor species identity using
  permutation tests.
\end{enumerate}

We load all necessary packages.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(lubridate)}
\KeywordTok{library}\NormalTok{(sf)}
\KeywordTok{library}\NormalTok{(forestecology)}
\KeywordTok{library}\NormalTok{(blockCV)}
\end{Highlighting}
\end{Shaded}

\hypertarget{compute-the-growth-of-trees-based-on-census-data}{%
\subsection{Compute the growth of trees based on census
data}\label{compute-the-growth-of-trees-based-on-census-data}}

The first step in the our analysis sequence is to compute the growth of
trees using data from two censuses. The \texttt{compute\_growth()}
function computes growth assuming census data that follows ForestGEO
standards. Despite such standards, minor variations will still exist
between sites thereby necessitating some data wrangling and checking.
For example, the SCBI site records all dbh's in millimeters, whereas the
Michigan Big Woods site records them in centimeters
\citet{andersonteixeira_ctfs-forestgeo_2015}
\citet{allen_michigan_2020}. The data format of other sites may be such
that our \texttt{compute\_growth()} function doesn't work at all.
However, in the end all that matters is that the growth of all trees is
saved in a data frame of class \texttt{sf} whereby the geolocation of
each tree is presented in a \texttt{geometry} variable of type
\texttt{\textless{}POINT\textgreater{}} and at a minimum the data
contains the following variables: a variable uniquely identifying each
tree-stem, \texttt{sp} of type \texttt{fct} factor identifying species,
\texttt{dbh1} and \texttt{dbh2} of type \texttt{dbl} quantifying the dbh
at earlier and later census, and \texttt{growth} of type \texttt{dbl}
double quantifying the average annual growth in centimeters.

We load both 2008 and 2014 SCBI census data \texttt{.csv} files as they
existed on GitHub on November 20, 2020. After selecting only relevant
variables, we perform a few additional data wrangling steps: convert the
variable with the date of measurement to be of type \texttt{date},
convert dbh to be in centimeters\footnote{A rule of thumb to determine
  the units of dbh is check if the smallest non-zero and non-missing
  measurement is 1 or 10. If the former, then centimeters. If the later,
  then millimeters. This is because ForestGEO protocols state that only
  trees with dbh greater or equal to 1cm should be included in censuses.},
convert the \texttt{sp} variable containing species information from
type \texttt{chr} character to \texttt{fct} factor (we will discuss the
need for this in Section \ref{spatial-cross-validation}). Furthermore,
in order to speed up computation for purposes of this examplt, we only
consider a 9 ha subsection of the 25.6 ha of the SCBI site: \texttt{gx}
from 0--300 instead of 0--400 and \texttt{gy} from 300--600 instead of
0--640.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{census_}\DecValTok{2013}\NormalTok{_scbi <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"scbi.stem2.csv"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(stemID, sp, }\DataTypeTok{date =}\NormalTok{ ExactDate, gx, gy, dbh, codes, status) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{date =} \KeywordTok{mdy}\NormalTok{(date),}
    \DataTypeTok{dbh =} \KeywordTok{as.numeric}\NormalTok{(dbh)}\OperatorTok{/}\DecValTok{10}\NormalTok{,}
    \DataTypeTok{sp =} \KeywordTok{factor}\NormalTok{(sp)}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(gx }\OperatorTok{<}\StringTok{ }\DecValTok{300}\NormalTok{, }\KeywordTok{between}\NormalTok{(gy, }\DecValTok{300}\NormalTok{, }\DecValTok{600}\NormalTok{))}

\NormalTok{census_}\DecValTok{2018}\NormalTok{_scbi <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"scbi.stem3.csv"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(stemID, sp, }\DataTypeTok{date =}\NormalTok{ ExactDate, gx, gy, dbh, codes, status) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{date =} \KeywordTok{mdy}\NormalTok{(date),}
    \DataTypeTok{dbh =} \KeywordTok{as.numeric}\NormalTok{(dbh)}\OperatorTok{/}\DecValTok{10}\NormalTok{,}
    \DataTypeTok{sp =} \KeywordTok{factor}\NormalTok{(sp)}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(gx }\OperatorTok{<}\StringTok{ }\DecValTok{300}\NormalTok{, }\KeywordTok{between}\NormalTok{(gy, }\DecValTok{300}\NormalTok{, }\DecValTok{600}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

These two data frames are then used as the two primary arguments to the
\texttt{compute\_growth()} function, along with the \texttt{id} argument
whereby the user specifies the name of the variable that uniquely
identifies each tree-stem under consideration (note this does not
include resprouts in the later census):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{growth_scbi <-}
\StringTok{  }\KeywordTok{compute_growth}\NormalTok{(}
    \DataTypeTok{census_1 =}\NormalTok{ census_}\DecValTok{2013}\NormalTok{_scbi,}
    \DataTypeTok{census_2 =}\NormalTok{ census_}\DecValTok{2018}\NormalTok{_scbi }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\KeywordTok{str_detect}\NormalTok{(codes, }\StringTok{"R"}\NormalTok{)),}
    \DataTypeTok{id =} \StringTok{"stemID"}
\NormalTok{  )}
\NormalTok{growth_scbi}
\CommentTok{## Simple feature collection with 7954 features and 8 fields}
\CommentTok{## geometry type:  POINT}
\CommentTok{## dimension:      XY}
\CommentTok{## bbox:           xmin: 0.2 ymin: 300 xmax: 299.9 ymax: 600}
\CommentTok{## CRS:            NA}
\CommentTok{## # A tibble: 7,954 x 9}
\CommentTok{##    stemID sp     dbh1 codes1 status  dbh2 codes2  growth     geometry}
\CommentTok{##     <dbl> <fct> <dbl> <chr>  <chr>  <dbl> <chr>    <dbl>      <POINT>}
\CommentTok{##  1      4 nysy  13.6  M      A       14.2 M       0.103  (14.2 428.5)}
\CommentTok{##  2      5 havi   8.8  M      A        9.6 M;P     0.150   (9.4 436.4)}
\CommentTok{##  3      6 havi   3.25 NULL   A        4   M       0.140     (1.3 434)}
\CommentTok{##  4     77 qual  65.2  M      A       66   M       0.141  (34.7 307.2)}
\CommentTok{##  5     79 tiam  47.7  M      A       46.8 M      -0.161    (40 381.1)}
\CommentTok{##  6     80 caca   5.15 M      A        6.5 M       0.253  (38.7 421.7)}
\CommentTok{##  7     96 libe   2.3  J;M    A        3.7 M       0.262      (60 310)}
\CommentTok{##  8    100 caca   5.09 NULL   A       NA   DN     NA      (52.5 476.3)}
\CommentTok{##  9    101 litu  65.4  M      A       68.4 M       0.552  (47.1 567.3)}
\CommentTok{## 10    102 astr   1.99 NULL   A        2.5 M       0.0954 (40.8 575.5)}
\CommentTok{## # ... with 7,944 more rows}
\end{Highlighting}
\end{Shaded}

The output \texttt{growth\_scbi} is a single data frame of class
\texttt{sf} that includes a numerical \texttt{growth} reflecting the
average annual growth in dbh (in cm) for all trees that were alive at
both time points as well a \texttt{geometry} variable encoding each
tree's geolocation. Furthermore, variables that (in theory) remain
unchanged between censuses appear only once, such as location variables
\texttt{gx} and \texttt{gy}; as well as species-related variables.
Variables that should change between censuses are suffixed with
\texttt{1} and \texttt{2} indicating the earlier and later censuses,
such as \texttt{dbh1/dbh2} and \texttt{codes1/codes2}.

Given that \texttt{growth\_scbi} is of class \texttt{sf}, it can be
easily plotted in \texttt{ggplot2} using the \texttt{geom\_sf()}
geometry as seen in Figure \ref{fig:scbi-trees}.

TODO: Rescale points in this plot:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_sf}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ growth_scbi, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{size =}\NormalTok{ growth)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{scale_size}\NormalTok{(}\DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\DataTypeTok{range =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.66\linewidth]{Figures/scbi-trees-1} 

}

\caption{Growth of trees at SCBI.}\label{fig:scbi-trees}
\end{figure}

\hypertarget{spatial-information}{%
\subsection{Add spatial information}\label{spatial-information}}

The next step in our analysis sequence is to add spatial information to
our main \texttt{growth\_scbi} data frame. The first element of spatial
information we add is a ``buffer region'' to the periphery of the study
region. Since some of our model's explanatory variables such as
competitor basal area are cumulative, we must ensure that all trees
being modeled are not biased to have different neighbor structures. This
is of particular concern for trees at the boundary of study regions,
which will not have the same number of neighbors that act as competitors
as trees in the internal part of the study region. In order to account
for such edge effects only trees who are not part of this buffer region,
i.e.~are part of the interior of the study region, will have their
growths modeled \citet{waller_applied_2004}.

Our model of interspecific competition relies on a spatial definition of
who the competitor trees are for focal trees of interest: all trees
within a distance \texttt{comp\_dist} of a focal tree are considered its
competitors (assuming the same units as the \texttt{gx} and \texttt{gy}
location variables). In our case we set this value below at 7.5m, a
value informed by \citet{canham_neighborhood_2004}
\citet{uriarte_spatially_2004} \citet{canham_neighborhood_2006}. Using
this value along with a manually constructed \texttt{sf} object
representation of the study region's boundary, we apply the
\texttt{add\_buffer\_variable()} to our \texttt{growth\_scbi} data frame
to add a \texttt{buffer} boolean variable: all trees who have
\texttt{buffer} set to \texttt{FALSE} will be our focal trees whose
growths are modeled, whereas those with \texttt{buffer} set to
\texttt{TRUE} will only be considered as competitor trees whose growth
will not be modeled.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Define buffer region using competitive distance range}
\NormalTok{comp_dist <-}\StringTok{ }\FloatTok{7.5}

\NormalTok{study_region_scbi <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{300}\NormalTok{, }\DecValTok{300}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{),}
  \DataTypeTok{y =} \KeywordTok{c}\NormalTok{(}\DecValTok{300}\NormalTok{, }\DecValTok{300}\NormalTok{, }\DecValTok{600}\NormalTok{, }\DecValTok{600}\NormalTok{, }\DecValTok{300}\NormalTok{)}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{sf_polygon}\NormalTok{()}

\NormalTok{growth_scbi <-}\StringTok{ }\NormalTok{growth_scbi }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{add_buffer_variable}\NormalTok{(}\DataTypeTok{size =}\NormalTok{ comp_dist, }\DataTypeTok{region =}\NormalTok{ study_region_scbi)}
\end{Highlighting}
\end{Shaded}

The second element of spatial information are blocks corresponding to
folds of a spatial cross-validation algorithm used to estimate model
error. Conventional cross-validation algorithms assign observations to
folds by randomly resampling individual observations. However,
underlying this algorithm is an assumption that the observations are
independent. In the case of forest census data, observations exhibit
spatial autocorrelation. This spatial dependence is incorporated into
the cross-validation algorithm by randomly resampling spatial blocks of
trees \citet{roberts_cross-validation_2017}
\citet{pohjankukka_estimating_2017}. We therefore associate each
observed tree to one of \(k\) spatial folds. In the example below, we
first manually define two folds that partition the study region as an
\texttt{sf} object. We then use the output of the
\texttt{spatialBlock()} function from the \texttt{blockCV} package to
associate each tree in \texttt{growth\_scbi} to the correct fold (saved
in the \texttt{foldID} variable) \citet{valavi_blockcv_2019}.
\textbackslash footnote\{In the Appendix we present an example where the
folds themselves are also created using the \texttt{spatialBlock()}
function given a specified \texttt{cv\_block\_size}.\}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Manually define spatial blocks to act as folds}
\NormalTok{fold1 <-}\StringTok{ }\KeywordTok{rbind}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{300}\NormalTok{), }\KeywordTok{c}\NormalTok{(}\DecValTok{150}\NormalTok{, }\DecValTok{300}\NormalTok{), }\KeywordTok{c}\NormalTok{(}\DecValTok{150}\NormalTok{, }\DecValTok{600}\NormalTok{), }\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{600}\NormalTok{))}
\NormalTok{fold2 <-}\StringTok{ }\KeywordTok{rbind}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{150}\NormalTok{, }\DecValTok{300}\NormalTok{), }\KeywordTok{c}\NormalTok{(}\DecValTok{300}\NormalTok{, }\DecValTok{300}\NormalTok{), }\KeywordTok{c}\NormalTok{(}\DecValTok{300}\NormalTok{, }\DecValTok{600}\NormalTok{), }\KeywordTok{c}\NormalTok{(}\DecValTok{150}\NormalTok{, }\DecValTok{600}\NormalTok{))}

\NormalTok{blocks_scbi <-}\StringTok{ }\KeywordTok{bind_rows}\NormalTok{(}
  \KeywordTok{sf_polygon}\NormalTok{(fold1),}
  \KeywordTok{sf_polygon}\NormalTok{(fold2)}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{folds =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{factor}\NormalTok{())}

\CommentTok{# Associate each observation to a fold}
\NormalTok{SpatialBlock_scbi <-}\StringTok{ }\KeywordTok{spatialBlock}\NormalTok{(}
  \DataTypeTok{speciesData =}\NormalTok{ growth_scbi, }\DataTypeTok{k =} \DecValTok{2}\NormalTok{, }\DataTypeTok{selection =} \StringTok{"systematic"}\NormalTok{, }
  \DataTypeTok{blocks =}\NormalTok{ blocks_scbi, }\DataTypeTok{showBlocks =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{verbose =} \OtherTok{FALSE}
\NormalTok{)}

\NormalTok{growth_scbi <-}\StringTok{ }\NormalTok{growth_scbi }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{foldID =}\NormalTok{ SpatialBlock_scbi}\OperatorTok{$}\NormalTok{foldID }\OperatorTok{%>%}\StringTok{ }\KeywordTok{factor}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:scbi-spatial-information} illustrates the net effect of
adding these two elements of information to the \texttt{growth\_scbi}
data frame. The location of each tree is marked with an integer
indicating which fold it belongs to, where the folds are marked with
solid lines. The color of each digit indicates whether the tree is part
of the buffer region (and thus will only be considered as a competitor
tree in our model) or is part of the interior of the study region (and
thus is a focal tree whose growth is of modeled interest).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_sf_text}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ growth_scbi, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{label =}\NormalTok{ foldID, }\DataTypeTok{col =}\NormalTok{ buffer), }\DataTypeTok{alpha =} \FloatTok{0.2}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_sf}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ blocks_scbi, }\DataTypeTok{fill =} \StringTok{"transparent"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.66\linewidth]{Figures/scbi-spatial-information-1} 

}

\caption{Buffer region and cross-validation block information for SCBI data.}\label{fig:scbi-spatial-information}
\end{figure}

TODO: Do we talk about
\texttt{add\_buffer\_variable(direction\ =\ "out")} when each fold gets
its turn being the training data?

\hypertarget{define-focal-versus-competitor-trees}{%
\subsection{Define focal versus competitor
trees}\label{define-focal-versus-competitor-trees}}

HEY BERT PICK IT UP HERE

Next we define \texttt{focal\_vs\_comp} data frames which connects each
focal tree in the \texttt{growth\_df} data frames to the trees in its
competitive neighborhood range as defined by the \texttt{comp\_dist}
constant. So for example, if \texttt{growth\_df} consisted of two focal
trees with two and three neighbors with \texttt{comp\_dist}
respectively, \texttt{focal\_vs\_comp} would be a data frame of 5 rows
connecting each focal tree to it's competitors. The
\texttt{create\_focal\_vs\_comp()} function makes this connection taking
as inputs the \texttt{growth\_df} data frame; the \texttt{comp\_dist}
constant defining competitive range; \texttt{cv\_grid\_sf}, giving the
cross validation grid; and the \texttt{id} variable.

\hypertarget{big-woods}{%
\subsubsection{Big Woods}\label{big-woods}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{focal_vs_comp_bw <-}\StringTok{ }\NormalTok{growth_bw }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{create_focal_vs_comp}\NormalTok{(comp_dist, }\DataTypeTok{cv_grid_sf =}\NormalTok{ blocks_bw, }\DataTypeTok{id =} \StringTok{"treeID"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

TODO: Figure out how to show this data frame's contents.

\hypertarget{scbi}{%
\subsubsection{SCBI}\label{scbi}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{focal_vs_comp_scbi <-}\StringTok{ }\NormalTok{growth_scbi }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{create_focal_vs_comp}\NormalTok{(comp_dist, }\DataTypeTok{cv_grid_sf =}\NormalTok{ blocks_scbi, }\DataTypeTok{id =} \StringTok{"stemID"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

TODO: Figure out how to show this data frame's contents.

\hypertarget{model-fit-predict}{%
\subsection{Fit model and make predictions}\label{model-fit-predict}}

Next we fit the following linear model to the dbh of each focal tree.
Let \(i = 1, \ldots, n_j\) index all \(n_j\) trees of ``focal'' species
group \(j\); let \(j = 1, \ldots, J\) index all \(J\) focal species
groups; and let \(k = 1, \ldots, K\) index all \(K\) ``competitor''
species groups. We modeled the growth in diameter per year \(y_{ij}\)
(in centimeters per year) of the \(i^{th}\) tree of focal species group
\(j\) as a linear model \(f\) of the following covariates
\(\vec{x}_{ij}\)

\[
\newcommand{\dbh}{\text{DBH}}
\newcommand{\biomass}{\text{biomass}}
\newcommand{\BA}{\text{BA}}
y_{ij} = f(\vec{x}_{ij}) + \epsilon_{ij} = \beta_{0,j} + \beta_{\dbh,j} \cdot \dbh_{ij} + \sum_{k=1}^{K} \lambda_{jk} \cdot \BA_{ijk} + \epsilon_{ij}
\]

We estimate the model's parameters using Bayesian linear regression
implemented in the \texttt{fit\_bayesian\_model()} function. TODO:
define all parameters

For this linear model's case, there exists a closed form solution as
described here. As such, the \texttt{fit\_bayesian\_model()} function
using matrix algebra to obtain all parameter estimates, rather than
computationally expensive Monte Carlo approximations. The inputs to this
function are a \texttt{focal\_vs\_comp} data frame,
\texttt{prior\_param} a list of priors, and a boolean flag
\texttt{run\_shuffle} on whether or not to run competitor-species
identity permutations which we will demonstrate below on the Michigan
Big Woods data. This function returns the posterior means of all
parameters.

Using these posterior means, we then use the posterior predictive
distribution to obtain fitted/predicted values \(\widehat{y}\) of the
dbh for each focal tree using the \texttt{predict\_bayesian\_model()}.
These \(\widehat{y}\) can then be compared to the observed \(y\) dbh's
to compute the root mean-square error, a measure of a model's predictive
error which has the same units as the observed data \(y\).

\hypertarget{big-woods-1}{%
\subsubsection{Big Woods}\label{big-woods-1}}

For the Michigan Big Woods data we present two use cases of the model
fitting and prediction scheme. The first use case is the simplest where
we assess the fit of the model using root mean squared error. The second
use case then answers the question of whether species competitor
identity matters using permutation test.

For the first use case, we fit the linear model specified in Equation
XXX to our data frame of type \texttt{focal\_vs\_comp}. This
input/outputs of the \texttt{fit\_bayesian\_model()} function are lists
of the prior/posterior means of parameters of the linear regression
specified in XXX. Generally speaking, there are two classes of
regression parameters: \(\beta\) main effects and \(\lambda\)
competitive effects. In the upcoming Section
\ref{viz-posterior-distributions}, we will present code visualizing this
posterior distributions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{comp_bayes_lm_bw <-}\StringTok{ }\NormalTok{focal_vs_comp_bw }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{comp_bayes_lm}\NormalTok{(}\DataTypeTok{prior_param =} \OtherTok{NULL}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This output of posterior parameters for the specified competition model
are then used along with the posterior predictive distribution encoded
in \texttt{predict\_bayesian\_model()} to return predicted growths for
each individual tree. We join these predicted growths to the original
growth data frame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{focal_vs_comp_bw <-}\StringTok{ }\NormalTok{focal_vs_comp_bw }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{growth_hat =} \KeywordTok{predict}\NormalTok{(comp_bayes_lm_bw, focal_vs_comp_bw))}
\end{Highlighting}
\end{Shaded}

We then use the \texttt{rmse()} function from the \texttt{yardstick}
package to obtain the root mean squared error of the observed versus
fitted values of growth.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{focal_vs_comp_bw }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rmse}\NormalTok{(}\DataTypeTok{truth =}\NormalTok{ growth, }\DataTypeTok{estimate =}\NormalTok{ growth_hat) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{(.estimate)}
\CommentTok{## [1] 0.148145}
\end{Highlighting}
\end{Shaded}

The second use case is near identical to the first, but with a small
change in the code to test whether the identity of the competitor
matters. By adding a \texttt{run\_shuffle\ =\ TRUE} argument to
\texttt{fit\_bayesian\_model()}, for each focal tree its competitor
trees' species identity will be ``shuffled'' randomly much like in a
permutation test. By shuffling these species labels we are effectively
fitting the model under a null model that competitor species identity
does not matter. If the ``shuffled'' RMSE's are consistently lower than
the unshuffled RMSE corresponding to the observed data, then we have
evidence to suggest that competitor identity matters to competitive
interactions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{comp_bayes_lm_bw_shuffle <-}\StringTok{ }\NormalTok{focal_vs_comp_bw }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{comp_bayes_lm}\NormalTok{(}\DataTypeTok{prior_param =} \OtherTok{NULL}\NormalTok{, }\DataTypeTok{run_shuffle =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{focal_vs_comp_bw <-}\StringTok{ }\NormalTok{focal_vs_comp_bw }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{growth_hat_shuffle =} \KeywordTok{predict}\NormalTok{(comp_bayes_lm_bw_shuffle, focal_vs_comp_bw))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{focal_vs_comp_bw }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rmse}\NormalTok{(}\DataTypeTok{truth =}\NormalTok{ growth, }\DataTypeTok{estimate =}\NormalTok{ growth_hat_shuffle) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{(.estimate)}
\CommentTok{## [1] 0.1505383}
\end{Highlighting}
\end{Shaded}

The RMSE is fact lower for the non-shuffled version, indicative of a
better model fit. This gives support for the idea that competitor
identity does matter for competitive interactions. In
\citet{allen_permutation_2020} we run this shuffle a large number of
times to construct a full permutation distribution to show that this
difference is robust to resampling variation.

\hypertarget{scbi-1}{%
\subsubsection{SCBI}\label{scbi-1}}

In the case of the SCBI data, we once again perform the same model
fitting and computing of fitted growths as with the Big Woods data, but
this time we map the residuals of the observed minus fitted values to
look for spatial patterns.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{comp_bayes_lm_scbi <-}\StringTok{ }\NormalTok{focal_vs_comp_scbi }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{comp_bayes_lm}\NormalTok{(}\DataTypeTok{prior_param =} \OtherTok{NULL}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{focal_vs_comp_scbi <-}\StringTok{ }\NormalTok{focal_vs_comp_scbi }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{growth_hat =} \KeywordTok{predict}\NormalTok{(comp_bayes_lm_scbi, focal_vs_comp_scbi))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{focal_vs_comp_scbi }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rmse}\NormalTok{(}\DataTypeTok{truth =}\NormalTok{ growth, }\DataTypeTok{estimate =}\NormalTok{ growth_hat) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{(.estimate)}
\CommentTok{## [1] 0.1281398}
\end{Highlighting}
\end{Shaded}

In Figures \ref{fig:scbi-model-residuals} and
\ref{fig:scbi-model-residuals-2} we present the residuals.

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{Figures/scbi-model-residuals-1} 

}

\caption{Predicted versus observed growth.}\label{fig:scbi-model-residuals}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{Figures/scbi-model-residuals-2-1} 

}

\caption{Spatial distribution of residuals for model applied to SCBI data.}\label{fig:scbi-model-residuals-2}
\end{figure}

\hypertarget{viz-posterior-distributions}{%
\subsection{Visualize model results}\label{viz-posterior-distributions}}

Lastly, we return to the model fits from Section \ref{model-fit-predict}
and present tools to visually explore the posterior distributions of all
parameters in our model. There are two main groups of parameters to
consider. The \(\beta\) coefficients tell us about how fast each species
grows and how this depends on DBH while the full matrix of \(\lambda\)
values describe the competitive effects between pairs of species. There
is a rich literature on this matrix (cite).

DO WE NEED TO DESCRIBE MECHANICS? Because of the structure of the
\texttt{bw\_fit\_model} object we cannot simply draw these curves based
on the posterior distribution. \texttt{bw\_fit\_model()} gives the
parameters \emph{compared} to a baseline. This is not of direct
interest. So to display these parameters, as we care about them, we have
to sample from the baseline distribution and from the comparison one to
get the posterior distribution of interest.

\hypertarget{big-woods-2}{%
\subsubsection{Big Woods}\label{big-woods-2}}

Here we re-run the model fit to the Big Woods data from Section
\ref{model-fit-predict}, but this time use ``family'' as the group for
comparison which has. This makes the posterior distributions easier to
follow. Also, surprisingly, grouping by family performed just as well as
grouping by species \citet{allen_permutation_2020}. First we re-run
\texttt{create\_focal\_vs\_comp()} and \texttt{fit\_bayesian\_model()}
with no permutation shuffling with the grouping variable as family.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{focal_vs_comp_bw <-}\StringTok{ }\NormalTok{growth_bw }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{sp =}\NormalTok{ family }\OperatorTok{%>%}\StringTok{ }\KeywordTok{factor}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{create_focal_vs_comp}\NormalTok{(}\DataTypeTok{comp_dist =}\NormalTok{ comp_dist, }\DataTypeTok{cv_grid_sf =}\NormalTok{ blocks_bw, }\DataTypeTok{id =} \StringTok{"treeID"}\NormalTok{)}

\NormalTok{comp_bayes_lm_bw <-}\StringTok{ }\NormalTok{focal_vs_comp_bw }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{comp_bayes_lm}\NormalTok{(}\DataTypeTok{prior_param =} \OtherTok{NULL}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now the posterior parameter outputs of \texttt{fit\_bayesian\_model()}
are passed to \texttt{plot\_bayesian\_model\_parameters()} to generate
visualizations of the posterior parameters. These visualizations are
displayed in Figure 5 of \citet{allen_permutation_2020}. For simplicity
we only plot a subset of the species families.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sp_to_plot <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"cornaceae"}\NormalTok{, }\StringTok{"fagaceae"}\NormalTok{, }\StringTok{"hamamelidaceae"}\NormalTok{, }\StringTok{"juglandaceae"}\NormalTok{, }
                 \StringTok{"lauraceae"}\NormalTok{, }\StringTok{"rosaceae"}\NormalTok{, }\StringTok{"sapindaceae"}\NormalTok{, }\StringTok{"ulmaceae"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The output is a list with three plots stored. Figure
\ref{fig:bw-posterior-viz-beta0} The element \texttt{beta\_0} gives the
baseline growth intercept \(\beta_0\), i.e., how fast an individual of
each group grows independent of DBH).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plot1 <-}\StringTok{ }\KeywordTok{autoplot}\NormalTok{(comp_bayes_lm_bw, }\DataTypeTok{type =} \StringTok{"intercepts"}\NormalTok{)}
\NormalTok{plot1}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{Figures/bw-posterior-viz-beta0-1} 

}

\caption{Posterior distribution of beta0.}\label{fig:bw-posterior-viz-beta0}
\end{figure}

Figure \ref{fig:bw-posterior-viz-beta-dbh} Next \texttt{beta\_dbh} gives
the slope for DBH slope \(\beta_{dbh,i}\) for each group.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plot2 <-}\StringTok{ }\KeywordTok{autoplot}\NormalTok{(comp_bayes_lm_bw, }\DataTypeTok{type =} \StringTok{"dbh_slopes"}\NormalTok{)}
\NormalTok{plot2}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{Figures/bw-posterior-viz-beta-dbh-1} 

}

\caption{Posterior distribution of betadbh.}\label{fig:bw-posterior-viz-beta-dbh}
\end{figure}

Finally Figure \ref{fig:bw-posterior-viz-lambda} \texttt{lambda} gives
the competition coefficients \(\lambda\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plot3 <-}\StringTok{ }\KeywordTok{autoplot}\NormalTok{(comp_bayes_lm_bw, }\DataTypeTok{type =} \StringTok{"competition"}\NormalTok{)}
\NormalTok{plot3}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{Figures/bw-posterior-viz-lambda-1} 

}

\caption{Posterior distribution of lambda's for Big Woods.}\label{fig:bw-posterior-viz-lambda}
\end{figure}

\hypertarget{scbi-2}{%
\subsubsection{SCBI}\label{scbi-2}}

We revisit the posterior parameters for the SCBI from Section
\{model-fit-predict\}, but this time only focus on the \(\lambda\)
competition coefficients.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sp_to_plot <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"quru"}\NormalTok{, }\StringTok{"litu"}\NormalTok{, }\StringTok{"cagl"}\NormalTok{, }\StringTok{"cato"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plot3 <-}\StringTok{ }\KeywordTok{autoplot}\NormalTok{(comp_bayes_lm_bw, }\DataTypeTok{type =} \StringTok{"competition"}\NormalTok{)}
\NormalTok{plot3}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{Figures/scbi-posterior-viz-lambda-1} 

}

\caption{Posterior distribution of lambda's for SCBI.}\label{fig:scbi-posterior-viz-lambda}
\end{figure}

Add explanation here.

HEY BERT PICK IT UP HERE

\hypertarget{spatial-cross-validation}{%
\subsection{Run spatial
cross-validation}\label{spatial-cross-validation}}

The model fits and predictions in Section \ref{model-fit-predict} all
suffer from a common failing: they use the same data to both fit the
model and to assess the model's performance using the RMSE. As argued by
\citet{roberts_cross-validation_2017}, this can lead to overly
optimistic assessments of model quality as the models can be overfit, in
particular in situations where spatial-autocorrelation is present. To
mitigate the effects of such overfitting, we use a spatially block
cross-validation algorithm implemented in the \texttt{run\_cv()}. This
function at its core uses the same model fitting implemented in the
\texttt{fit\_bayesian\_model()} function, however trains the model on
\(k-1\) spatial folds of the train and returns fitted values for the
test data. Recall that the spatial blocking scheme wass encoded in
Section \ref{spatial-information}.

\hypertarget{big-woods-3}{%
\subsubsection{Big Woods}\label{big-woods-3}}

Applying this spatially cross-validated model fit yields an RMSE is
higher than that when the model is fit without cross validation. In
other words, our model fits in \ref{model-fit-predict} were overly
optimistic in the model's fitting power, whereas a cross-validated
results yield an estimate that is closer to the truth. See
\citet{allen_permutation_2020} for more discussion of this.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{focal_vs_comp_bw <-}\StringTok{ }\NormalTok{focal_vs_comp_bw }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{run_cv}\NormalTok{(}\DataTypeTok{comp_dist =}\NormalTok{ comp_dist, }\DataTypeTok{cv_grid =}\NormalTok{ blocks_bw)}

\NormalTok{focal_vs_comp_bw }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rmse}\NormalTok{(}\DataTypeTok{truth =}\NormalTok{ growth, }\DataTypeTok{estimate =}\NormalTok{ growth_hat) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{(.estimate)}
\CommentTok{## [1] 0.1532316}
\end{Highlighting}
\end{Shaded}

\hypertarget{scbi-3}{%
\subsubsection{SCBI}\label{scbi-3}}

Observe once again that this RMSE is much higher than that for the above
SCBI model fit without cross-validation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{focal_vs_comp_scbi <-}\StringTok{ }\NormalTok{focal_vs_comp_scbi }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{run_cv}\NormalTok{(}\DataTypeTok{comp_dist =}\NormalTok{ comp_dist, }\DataTypeTok{cv_grid =}\NormalTok{ blocks_scbi)}

\NormalTok{focal_vs_comp_scbi }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rmse}\NormalTok{(}\DataTypeTok{truth =}\NormalTok{ growth, }\DataTypeTok{estimate =}\NormalTok{ growth_hat) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{pull}\NormalTok{(.estimate)}
\CommentTok{## [1] 0.144608}
\end{Highlighting}
\end{Shaded}

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

\hypertarget{acknowledgments}{%
\section{Acknowledgments}\label{acknowledgments}}

\bibliographystyle{agsm}
\bibliography{paper.bib}

\end{document}
