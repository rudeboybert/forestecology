---
title: "The `forestecology` R package for modeling interspecies competition between trees"

# to produce blinded version set to 1 and change blinded <- TRUE on line 54 below
blinded: 0

authors: 
- name: Albert Y. Kim 
  thanks: "Albert Y. Kim is Assistant Professor, Statistical & Data Sciences, Smith College, Northampton, MA 01063 (e-mail: akim04@smith.edu)."
  affiliation: Program in Statistical & Data Sciences, Smith College
  
- name: David Allen
  affiliation: Biology Department, Middlebury College
  
- name: Simon P. Couch
  affiliation: Mathematics Department, Reed College

abstract: 
- "Move abstract below here after completed."

keywords:
- forest ecology, competition, R, Rstats, tidyverse, sf, cross-validation, 

bibliography: paper.bib
output: rticles::asa_article
link-citations: yes
header-includes:
- \usepackage{xcolor, soul, xspace, float, subfig, lineno}
---

\linenumbers

```{r setup, include = FALSE, cache = FALSE}
# Internally used packages
library(viridis)
library(knitr)
library(ggplot2)
library(here)
library(tibble)

# knitr settings
opts_chunk$set(
  # Code output:
  warning = FALSE,
  message = FALSE,
  echo = TRUE,
  cache = TRUE,
  # Figure:
  out.width = "100%",
  fig.path = "Figures/",
  fig.width = 16 / 2.5,
  fig.height = 9 / 2.5,
  fig.align = "center",
  fig.show = "hold",
  # Etc:
  collapse = TRUE,
  comment = "##",
  # tidy = FALSE,
  tibble.print_max = 5,
  tibble.print_min = 5
)

# Random number generator seed value
set.seed(76)

# Set ggplot defaults output:
if (!is_html_output()) {
  # Grey theme:
  ggplot2::theme_set(theme_light())
  # Color scheme
  # scale_colour_discrete <- scale_colour_viridis_d
}

# Set output width
options(width = 70)
```

# Abstract (350 words) {-}

1. When modeling growth of trees forest ecologists often incorporate the effect of interspecies competition. Many such models are based on a neighborhood effect assumption whereby all trees within a fixed distance of all focal trees are considered competitors. Methods are needed to evaluate the effect of interspecies competition and to assess their quality. 
1. We present the `forestecology` package providing methods for both 1) evaluating the out-of-sample performance of our model using spatial-crossvaliation and 2) testing a null hypothesis of of no impact of competitor species' identity on the growth of trees using a permutation test. We implement a class and methods using R's S3 object-oriented system, for a specific linear, Bayesian neighborhood competition model of tree growth. 
1. We demonstrate the package's functions using data from the Smithsonian Conservation Biology Institute's large forest dynamics plot, part of the ForestGEO network of reseach sites. Given ForestGEO's data collection protocols and data formatting standards, the package cross-compatibility of code. We show both that 1) competitor species identity matters and 2) that not spatially cross-validating leads to error estimates that are overly optimistic. 
1. The package follows `tidyverse`-like structure whereby verb-named functions can be modularly "piped" in sequence to intuitively display the sequence of steps of analysis from start to finish. Additionally, most inputs/outputs of functions assume an are of `sf` class from the simple features package, thereby facilitating all wrangling and visualization of geospatial data. Lastly, even though our package is currently limited to one specific model, the package is setup such that it can be easily extended to other models. 




# Introduction

Repeat-censused forest plots offer excellent data to test neighborhood models of tree competition @allen_permutation_2020 @canham_neighborhood_2006 @uriarte_spatially_2004. Here we describe an R package, `forestecology`, to do that. This package implements the methods in @allen_permutation_2020. It provides: a convenient way to specify and fit models of tree growth based on neighborhood competition; a spatial cross validation method to test and compare model fits @roberts_cross-validation_2017; and an ANOVA-like method to assess whether the competitor identity matters in these models. The model is written to work with ForestGEO plot data @andersonteixeira_ctfs-forestgeo_2015, but we envision that it could easily be modified to work with data from other forest plots, e.g. the US Forest Service Forest Inventory and Analysis plots @smith_forest_2002.



The `forestecology` is designed with "tidy" data principles in mind as @wickham_welcome_2019.

Given that our data is of geo-spatial nature, we represent our data using the "simple features" `sf` package class of objects @pebesma_simple_2018 whereby. While previously the `sp` package serves such purposes @pebesma_sp_2005, the `sf` package is designed to interface with the `tidyverse` suite of packages.

## Model

Describe model specifics.




# Example

We demonstrate the `forestecology` package's features on the Smithsonian Conservation Biology Institute (SCBI) large forest dynamics plot, located at the Smithsonian's National Zoo and Conservation Biology Institute in Front Royal, VA, USA. The 25.6 ha (640 x 400 m) plot is located at the intersection of three of the major physiographic provinces of the eastern US: the Blue Ridge, Ridge and Valley, and Piedmont provinces and is adjacent to the northern end of Shenandoah National Park. The forest type is typical mature secondary eastern mixed deciduous forest, with a canopy dominated by tulip poplar (*Liriodendron tulipifera*), oaks (*Quercus* spp.), and hickories (*Carya* spp.), and an understory composed mainly of spicebush (*Lindera benzoin*), paw-paw (*Asimina triloba*), American hornbeam (*Carpinus caroliniana*), and witch hazel (*Hamamelis virginiana*) @bourg_initial_2013. 

A high-level overview of the steps of our analysis pipeline is as follows:

1. Compute the growth of trees based on census data
1. Add spatial information:
    1. Define buffer region trees.
    1. Add spatial cross-validation block information.
1. Identify all focal and corresponding competitor trees.
1. Fit model and make predictions.
1. Additionally: Evaluate model performance using spatial cross-validation.
1. Additionally: Evaluate the effect of competitor species identity using permutation tests.


We load all necessary packages.

```{r load-packages}
library(tidyverse)
library(lubridate)
library(sf)
library(forestecology)
library(blockCV)
```



## Compute the growth of trees based on census data

The first step in the our analysis sequence is to compute the growth of trees using data from two censuses. The `compute_growth()` function computes growth assuming census data that follows ForestGEO standards. Despite such standards, minor variations will still exist between sites thereby necessitating some data wrangling and checking. For example, the SCBI site records all DBH's in millimeters, whereas the Michigan Big Woods site records them in centimeters @andersonteixeira_ctfs-forestgeo_2015 @allen_michigan_2020. The data format of other sites may be such that our `compute_growth()` function doesn't work at all. However, in the end all that matters is that the growth of all trees is saved in a data frame of class `sf` whereby the geolocation of each tree is presented in a `geometry` variable of type `<POINT>` and at a minimum the data contains the following variables: a variable uniquely identifying each tree-stem, `sp` of type `fct` factor identifying species, `dbh1` and `dbh2` of type `dbl` quantifying the DBH at earlier and later census, and `growth` of type `dbl` double quantifying the average annual growth in centimeters. 

We load both 2008 and 2014 SCBI census data `.csv` files as they existed on GitHub on November 20, 2020. After selecting only relevant variables, we perform a few additional data wrangling steps: convert the variable with the date of measurement to be of type `date`, convert DBH to be in centimeters^[A rule of thumb to determine the units of DBH is check if the smallest non-zero and non-missing measurement is 1 or 10. If the former, then centimeters. If the later, then millimeters. This is because ForestGEO protocols state that only trees with DBH greater or equal to 1cm should be included in censuses.], convert the `sp` variable containing species information from type `chr` character to `fct` factor (we will discuss the need for this in Section \ref{spatial-cross-validation}). Furthermore, in order to speed up computation for purposes of this example, we only consider a 9 ha subsection of the 25.6 ha of the SCBI site: `gx` from 0--300 instead of 0--400 and `gy` from 300--600 instead of 0--640.

```{r scbi-load-data}
census_2013_scbi <- read_csv("scbi.stem2.csv") %>%
  select(stemID, sp, date = ExactDate, gx, gy, dbh, codes, status) %>%
  mutate(
    date = mdy(date),
    dbh = as.numeric(dbh)/10,
    sp = factor(sp)
  ) %>%
  filter(gx < 300, between(gy, 300, 600))

census_2018_scbi <- read_csv("scbi.stem3.csv") %>%
  select(stemID, sp, date = ExactDate, gx, gy, dbh, codes, status) %>%
  mutate(
    date = mdy(date),
    dbh = as.numeric(dbh)/10,
    sp = factor(sp)
  ) %>%
  filter(gx < 300, between(gy, 300, 600))
```

These two data frames are then used as the two primary arguments to the `compute_growth()` function, along with the `id` argument whereby the user specifies the name of the variable that uniquely identifies each tree-stem under consideration (note this does not include resprouts in the later census):

```{r scbi-compute-growth}
growth_scbi <-
  compute_growth(
    census_1 = census_2013_scbi,
    census_2 = census_2018_scbi %>% filter(!str_detect(codes, "R")),
    id = "stemID"
  )
growth_scbi
```

The output `growth_scbi` is a single data frame of class `sf` that includes a numerical `growth` reflecting the average annual growth in DBH (in cm) for all trees that were alive at both time points as well a `geometry` variable encoding each tree's geolocation. Furthermore, variables that (in theory) remain unchanged between censuses appear only once, such as location variables `gx` and `gy`; as well as species-related variables. Variables that should change between censuses are suffixed with `1` and `2` indicating the earlier and later censuses, such as `dbh1/dbh2` and `codes1/codes2`. 

Given that `growth_scbi` is of class `sf`, it can be easily plotted in `ggplot2` using the `geom_sf()` geometry as seen in Figure \ref{fig:scbi-trees}.

TODO: Rescale points in this plot:

```{r scbi-trees, out.width="66%", fig.cap="Growth of trees at SCBI."}
ggplot() +
  geom_sf(data = growth_scbi, aes(size = growth)) + 
  scale_size(breaks = c(0.01, 0.1, 1), range = c(0.1, 1))
```



## Add spatial information {#spatial-information}

The next step in our analysis sequence is to add spatial information to our main `growth_scbi` data frame. The first element of spatial information we add is a "buffer region" to the periphery of the study region. Since some of our model's explanatory variables such as competitor basal area are cumulative, we must ensure that all trees being modeled are not biased to have different neighbor structures. This is of particular concern for trees at the boundary of study regions, which will not have the same number of neighbors that act as competitors as trees in the internal part of the study region. In order to account for such edge effects only trees who are not part of this buffer region, i.e. are part of the interior of the study region, will have their growths modeled @waller_applied_2004.

Our model of interspecific competition relies on a spatial definition of who the competitor trees are for focal trees of interest: all trees within a distance `comp_dist` of a focal tree are considered its competitors (assuming the same units as the `gx` and `gy` location variables). In our case we set this value below at 7.5m, a value informed by @canham_neighborhood_2004 @uriarte_spatially_2004 @canham_neighborhood_2006. Using this value along with a manually constructed `sf` object representation of the study region's boundary, we apply the `add_buffer_variable()` to our `growth_scbi` data frame to add a `buffer` boolean variable: all trees who have `buffer` set to `FALSE` will be our focal trees whose growths are modeled, whereas those with `buffer` set to `TRUE` will only be considered as competitor trees whose growth will not be modeled. 

```{r}
# Define buffer region using competitive distance range
comp_dist <- 7.5

study_region_scbi <- tibble(
  x = c(0, 300, 300, 0, 0),
  y = c(300, 300, 600, 600, 300)
) %>%
  sf_polygon()

growth_scbi <- growth_scbi %>%
  add_buffer_variable(size = comp_dist, region = study_region_scbi)
```

The second element of spatial information are blocks corresponding to folds of a spatial cross-validation algorithm used to estimate model error. Conventional cross-validation algorithms assign observations to folds by randomly resampling individual observations. However, underlying this algorithm is an assumption that the observations are independent. In the case of forest census data, observations exhibit spatial autocorrelation. This spatial dependence is incorporated into the cross-validation algorithm by randomly resampling spatial blocks of trees @roberts_cross-validation_2017 @pohjankukka_estimating_2017. We therefore associate each observed tree to one of $k$ spatial folds. In the example below, we first manually define two folds that partition the study region as an `sf` object. We then use the output of the `spatialBlock()` function from the `blockCV` package to associate each tree in `growth_scbi` to the correct fold (saved in the `foldID` variable) @valavi_blockcv_2019. \footnote{In the Appendix we present an example where the folds themselves are also created using the `spatialBlock()` function given a specified `cv_block_size`.} 

```{r}
# Manually define spatial blocks to act as folds
fold1 <- rbind(c(0, 300), c(150, 300), c(150, 600), c(0, 600))
fold2 <- rbind(c(150, 300), c(300, 300), c(300, 600), c(150, 600))

blocks_scbi <- bind_rows(sf_polygon(fold1), sf_polygon(fold2)) %>%
  mutate(folds = c(1, 2) %>% factor())

# Associate each observation to a fold
SpatialBlock_scbi <- spatialBlock(
  speciesData = growth_scbi, k = 2, selection = "systematic", 
  blocks = blocks_scbi, showBlocks = FALSE, verbose = FALSE
)

growth_scbi <- growth_scbi %>%
  mutate(foldID = SpatialBlock_scbi$foldID %>% factor())
```

Figure \ref{fig:scbi-spatial-information} illustrates the net effect of adding these two elements of information to the `growth_scbi` data frame. The location of each tree is marked with an integer indicating which fold it belongs to, where the folds are marked with solid lines. The color of each digit indicates whether the tree is part of the buffer region (and thus will only be considered as a competitor tree in our model) or is part of the interior of the study region (and thus is a focal tree whose growth is of modeled interest).

```{r scbi-spatial-information, out.width="66%", fig.cap="Buffer region and cross-validation block information for SCBI data."}
ggplot() +
  geom_sf_text(data = growth_scbi, aes(label = foldID, col = buffer), 
               alpha = 0.2) +
  geom_sf(data = blocks_scbi, fill = "transparent")
```

TODO: Do we talk about `add_buffer_variable(direction = "out")` when each fold gets its turn being the training data?



## Identify all focal and corresponding competitor trees

The next step in our analysis sequence is to identify all focal trees and their corresponding competitor trees. The `create_focal_vs_comp()` functions performs these tasks and returns a new data frame of type `sf` containing this information. On top of the previously discussed arguments `comp_dist` defining the competition neighborhood and `id` indicating which variable in the data frame uniquely identifies each tree-stem, this function also requires an `sf` object representation of the spatial cross-validation blocks/folds; in our case, this was manually encoded in the `blocks_scbi` in Section \ref{spatial-information} while in our Appendix we present an example where this was performed using `spatialBlock()` from the `blockCV` package. We present the resulting data frame below with the `foldID` variable omitted for compactness of presentation.

```{r scbi-focal-vs-comp}
focal_vs_comp_scbi <- growth_scbi %>%
  create_focal_vs_comp(comp_dist, cv_grid_sf = blocks_scbi, id = "stemID")
focal_vs_comp_scbi %>% 
  select(-foldID)
```

TODO: Below reconcile the number of rows as they off by one from `growth_scbi` pipe `filter(!is.na(growth) & !buffer)`. perhaps by removing NA's in the `growth_scbi` stage.

The resulting data frame `focal_vs_comp_scbi` has `r nrow(focal_vs_comp_scbi)` rows, representing the subset of the `r nrow(growth_scbi)` trees in `growth_scbi` that will be considered as focal trees and thus have their growths modeled. Recall from Section \ref{spatial-information} this consists all trees that are not part of the buffer region in Figure \ref{fig:scbi-spatial-information}. Two new variables `focal_ID` and `focal_sp` related to tree-stem identification and species information. Most notably however is a new variable `comp` which contains information on all competitor trees for a given focal tree saved in list-column format, a feature of the `tidyr` package @tidyr_package. For example, we drill-down on the tree with `focal_ID` equal to 4. It has 20 competitor trees each described by 4 variables as indicated by the fact that `comp` is a `<tibble [20 Ã— 4]>`. 

```{r scbi-focal-vs-comp-2}
focal_vs_comp_scbi %>% 
  filter(focal_ID == 4) %>% 
  select(focal_ID, dbh, comp)
```

Using the `unnest()` function from the `tidyr` package, we can flatten list-column into regular columns. We observe that for the same focal tree with DBH equal to 13.65cm, we have information on all 20 competitor trees whose `dist` distance to the focal tree is less than or equal to `r comp_dist`, including their unique tree-stem ID number, their species, and their basal area (in m$^2$) calculated as $\frac{\pi \times (\text{DBH/2})^2}{10000}$ where $DBH$ is the value from the earlier census in cm. Saving our focal versus competitor information in list-column minimizes redundancy since we do not repeat information on the focal tree 20 times. 

```{r, eval = FALSE}
focal_vs_comp_scbi %>% 
  filter(focal_ID == 4) %>% 
  select(focal_ID, dbh, comp) %>% 
  unnest(cols = "comp")
```
```{r scbi-focal-vs-comp-3, echo = FALSE}
# Not sure why we need to do things this way:
focal_vs_comp_scbi %>% 
  filter(focal_ID == 4) %>% 
  select(focal_ID, dbh, comp) %>% 
  unnest(cols = "comp") %>% 
  print(n = 5)
```



## Fit model and make predictions {#model-fit-predict}

HEY BERT PICK IT UP HERE

Next we fit the following linear model to the DBH of each focal tree. Let $i = 1, \ldots, n_j$ index all $n_j$ trees of "focal" species group $j$; let $j = 1, \ldots, J$ index all $J$ focal species groups; and let $k = 1, \ldots, K$ index all $K$ "competitor" species groups. We modeled the growth in diameter per year $y_{ij}$ (in centimeters per year) of the $i^{th}$ tree of focal species group $j$ as a linear model $f$ of the following covariates $\vec{x}_{ij}$

$$
\newcommand{\dbh}{\text{DBH}}
\newcommand{\biomass}{\text{biomass}}
\newcommand{\BA}{\text{BA}}
y_{ij} = f(\vec{x}_{ij}) + \epsilon_{ij} = \beta_{0,j} + \beta_{\dbh,j} \cdot \dbh_{ij} + \sum_{k=1}^{K} \lambda_{jk} \cdot \BA_{ijk} + \epsilon_{ij}
$$

<!--where $\beta_{0,j}$ is the diameter-independent growth rate for group $j$; $\dbh_{ij}$ is the diameter at breast height (in centimeters) of the focal tree at the earlier census; $\beta_{\dbh,j}$ is the amount of the growth rate changed depending on diameter for group $j$;  $\BA_{ijk}$ is the sum of the basal area of all trees of competitor species group $k$; $\lambda_{jk}$ is the change in growth for individuals of group $j$ from nearby competitors of group $k$; and $\epsilon_{ij}$ is a random error term distributed $\text{Normal}(0, \sigma^2)$.-->

We estimate the model's parameters using Bayesian linear regression implemented in the `fit_bayesian_model()` function. TODO: define all parameters

For this linear model's case, there exists a closed form solution as described here. As such, the `fit_bayesian_model()` function using matrix algebra to obtain all parameter estimates, rather than computationally expensive Monte Carlo approximations. The inputs to this function are a `focal_vs_comp` data frame, `prior_param` a list of priors, and a boolean flag `run_shuffle` on whether or not to run competitor-species identity permutations which we will demonstrate below on the Michigan Big Woods data. This function returns the posterior means of all parameters.

Using these posterior means, we then use the posterior predictive distribution to obtain fitted/predicted values $\widehat{y}$ of the DBH for each focal tree using the `predict_bayesian_model()`. These $\widehat{y}$ can then be compared to the observed $y$ DBH's to compute the root mean-square error, a measure of a model's predictive error which has the same units as the observed data $y$.

### Big Woods 

For the Michigan Big Woods data we present two use cases of the model fitting and prediction scheme. The first use case is the simplest where we assess the fit of the model using root mean squared error. The second use case then answers the question of whether species competitor identity matters using permutation test. 

For the first use case, we fit the linear model specified in Equation XXX to our data frame of type `focal_vs_comp`. This input/outputs of the `fit_bayesian_model()` function are lists of the prior/posterior means of parameters of the linear regression specified in XXX. Generally speaking, there are two classes of regression parameters: $\beta$ main effects and $\lambda$ competitive effects. In the upcoming Section \ref{viz-posterior-distributions}, we will present code visualizing this posterior distributions.

```{r bw-model-fit, eval=FALSE}
comp_bayes_lm_bw <- focal_vs_comp_bw %>%
  comp_bayes_lm(prior_param = NULL)
```

This output of posterior parameters for the specified competition model are then used along with the posterior predictive distribution encoded in `predict_bayesian_model()` to return predicted growths for each individual tree. We join these predicted growths to the original growth data frame. 

```{r bw-model-predict, eval=FALSE}
focal_vs_comp_bw <- focal_vs_comp_bw %>%
  mutate(growth_hat = predict(comp_bayes_lm_bw, focal_vs_comp_bw))
```

We then use the `rmse()` function from the `yardstick` package to obtain the root mean squared error of the observed versus fitted values of growth. 

```{r bw-model-rmse, eval=FALSE}
focal_vs_comp_bw %>%
  rmse(truth = growth, estimate = growth_hat) %>%
  pull(.estimate)
```

The second use case is near identical to the first, but with a small change in the code to test whether the identity of the competitor matters. By adding a `run_shuffle = TRUE` argument to `fit_bayesian_model()`, for each focal tree its competitor trees' species identity will be "shuffled" randomly much like in a permutation test. By shuffling these species labels we are effectively fitting the model under a null model that competitor species identity does not matter. If the "shuffled" RMSE's are consistently lower than the unshuffled RMSE corresponding to the observed data, then we have evidence to suggest that competitor identity matters to competitive interactions.

```{r bw-model-shuffle-fit, eval=FALSE}
comp_bayes_lm_bw_shuffle <- focal_vs_comp_bw %>%
  comp_bayes_lm(prior_param = NULL, run_shuffle = TRUE)
```

```{r bw-model-shuffle-predict, eval=FALSE}
focal_vs_comp_bw <- focal_vs_comp_bw %>%
  mutate(growth_hat_shuffle = predict(comp_bayes_lm_bw_shuffle, focal_vs_comp_bw))
```

```{r bw-model-shuffle-rmse, eval=FALSE}
focal_vs_comp_bw %>%
  rmse(truth = growth, estimate = growth_hat_shuffle) %>%
  pull(.estimate)
```

The RMSE is fact lower for the non-shuffled version, indicative of a better model fit. This gives support for the idea that competitor identity does matter for competitive interactions. In @allen_permutation_2020 we run this shuffle a large number of times to construct a full permutation distribution to show that this difference is robust to resampling variation.

### SCBI 

In the case of the SCBI data, we once again perform the same model fitting and computing of fitted growths as with the Big Woods data, but this time we map the residuals of the observed minus fitted values to look for spatial patterns. 

```{r scbi-model-fit, eval=FALSE}
comp_bayes_lm_scbi <- focal_vs_comp_scbi %>%
  comp_bayes_lm(prior_param = NULL)
```

```{r scbi-model-predict, eval=FALSE}
focal_vs_comp_scbi <- focal_vs_comp_scbi %>%
  mutate(growth_hat = predict(comp_bayes_lm_scbi, focal_vs_comp_scbi))
```

```{r scbi-model-rmse, eval=FALSE}
focal_vs_comp_scbi %>%
  rmse(truth = growth, estimate = growth_hat) %>%
  pull(.estimate)
```

In Figures \ref{fig:scbi-model-residuals} and \ref{fig:scbi-model-residuals-2} we present the residuals. 

```{r scbi-model-residuals, out.width="100%", fig.cap="Predicted versus observed growth.", echo = FALSE, eval=FALSE}
ggplot(focal_vs_comp_scbi, aes(x = growth, y = growth_hat)) +
  geom_point(size = 0.5, color = rgb(0, 0, 0, 0.25)) +
  stat_smooth(method = "lm") +
  geom_abline(slope = 1, intercept = 0) +
  coord_fixed() +
  labs(
    x = "Observed growth in DBH", y = "Predicted growth in DBH",
    title = "Predicted vs Observed Growth"
  )
```

```{r scbi-model-residuals-2, out.width="80%", fig.cap="Spatial distribution of residuals for model applied to SCBI data.", echo = FALSE, eval=FALSE}
focal_vs_comp_scbi %>%
  st_as_sf() %>%
  # TODO: Need to investigate missingness
  filter(!is.na(growth_hat)) %>%
  mutate(
    error = growth - growth_hat,
    error_bin = cut_number(error, n = 5),
    error_compress = ifelse(error < -0.75, -0.75, ifelse(error > 0.75, 0.75, error))
  ) %>%
  ggplot() +
  geom_sf(aes(col = error_compress), size = 1) +
  theme_bw() +
  scale_color_gradient2(
    low = "#ef8a62", mid = "#f7f7f7", high = "#67a9cf",
    name = expression(paste("Residual (cm ", y^{-1}, ")")),
    breaks = seq(from = -0.75, to = 0.75, by = 0.25),
    labels = c("< -0.75", "-0.5", "0.25", "0", "0.25", "0.5", "> 0.75")
  ) +
  labs(x = "Meter", y = "Meter")
```


## Visualize model results {#viz-posterior-distributions}

Lastly, we return to the model fits from Section \ref{model-fit-predict} and present tools to visually explore the posterior distributions of all parameters in our model. There are two main groups of parameters to consider. The $\beta$ coefficients tell us about how fast each species grows and how this depends on DBH while the full matrix of $\lambda$ values describe the competitive effects between pairs of species. There is a rich literature on this matrix (cite). 

DO WE NEED TO DESCRIBE MECHANICS? Because of the structure of the `bw_fit_model` object we cannot simply draw these curves based on the posterior distribution. `bw_fit_model()` gives the parameters *compared* to a baseline. This is not of direct interest. So to display these parameters, as we care about them, we have to sample from the baseline distribution and from the comparison one to get the posterior distribution of interest. 


### Big Woods 

Here we re-run the model fit to the Big Woods data from Section \ref{model-fit-predict}, but this time use "family" as the group for comparison which has. This makes the posterior distributions easier to follow. Also, surprisingly, grouping by family performed just as well as grouping by species @allen_permutation_2020. First we re-run `create_focal_vs_comp()` and `fit_bayesian_model()` with no permutation shuffling with the grouping variable as family.

```{r bw-posterior-viz-0, eval=FALSE}
focal_vs_comp_bw <- growth_bw %>%
  mutate(sp = family %>% factor()) %>%
  create_focal_vs_comp(comp_dist = comp_dist, cv_grid_sf = blocks_bw, id = "treeID")

comp_bayes_lm_bw <- focal_vs_comp_bw %>%
  comp_bayes_lm(prior_param = NULL)
```

Now the posterior parameter outputs of `fit_bayesian_model()` are passed to `plot_bayesian_model_parameters()` to generate visualizations of the posterior parameters. These visualizations are displayed in Figure 5 of @allen_permutation_2020. For simplicity we only plot a subset of the species families. 

```{r bw-posterior-viz-1, eval=FALSE}
sp_to_plot <- c("cornaceae", "fagaceae", "hamamelidaceae", "juglandaceae", 
                 "lauraceae", "rosaceae", "sapindaceae", "ulmaceae")
```

The output is a list with three plots stored. Figure \ref{fig:bw-posterior-viz-beta0} The element `beta_0` gives the baseline growth intercept $\beta_0$, i.e., how fast an individual of each group grows independent of DBH).

```{r bw-posterior-viz-beta0, out.width="100%", fig.cap="Posterior distribution of beta0.", eval=FALSE}
plot1 <- autoplot(comp_bayes_lm_bw, type = "intercepts")
plot1
```

Figure \ref{fig:bw-posterior-viz-beta-dbh} Next `beta_dbh` gives the slope for DBH slope $\beta_{dbh,i}$ for each group.

```{r bw-posterior-viz-beta-dbh, out.width="100%", fig.cap="Posterior distribution of betadbh.", eval=FALSE}
plot2 <- autoplot(comp_bayes_lm_bw, type = "dbh_slopes")
plot2
```

Finally Figure \ref{fig:bw-posterior-viz-lambda} `lambda` gives the competition coefficients $\lambda$.

```{r bw-posterior-viz-lambda, out.width="100%", fig.cap="Posterior distribution of lambda's for Big Woods.", eval=FALSE}
plot3 <- autoplot(comp_bayes_lm_bw, type = "competition")
plot3
```


### SCBI

We revisit the posterior parameters for the SCBI from Section {model-fit-predict}, but this time only focus on the $\lambda$ competition coefficients. 

```{r scbi-posterior-viz-1, eval=FALSE}
sp_to_plot <- c("quru", "litu", "cagl", "cato")
```

```{r scbi-posterior-viz-lambda, out.width="100%", fig.cap="Posterior distribution of lambda's for SCBI.", eval=FALSE}
plot3 <- autoplot(comp_bayes_lm_bw, type = "competition")
plot3
```

Add explanation here. 

HEY BERT PICK IT UP HERE




## Run spatial cross-validation {#spatial-cross-validation}

The model fits and predictions in Section \ref{model-fit-predict} all suffer from a common failing: they use the same data to both fit the model and to assess the model's performance using the RMSE. As argued by @roberts_cross-validation_2017, this can lead to overly optimistic assessments of model quality as the models can be overfit, in particular in situations where spatial-autocorrelation is present. To mitigate the effects of such overfitting, we use a spatially block cross-validation algorithm implemented in the `run_cv()`. This function at its core uses the same model fitting implemented in the `fit_bayesian_model()` function, however trains the model on $k-1$ spatial folds of the train and returns fitted values for the test data. Recall that the spatial blocking scheme wass encoded in Section \ref{spatial-information}.

### Big Woods

Applying this spatially cross-validated model fit yields an RMSE is higher than that when the model is fit without cross validation. In other words, our model fits in \ref{model-fit-predict} were overly optimistic in the model's fitting power, whereas a cross-validated results yield an estimate that is closer to the truth. See @allen_permutation_2020 for more discussion of this. 

```{r bw-spatial-cv, eval=FALSE}
focal_vs_comp_bw <- focal_vs_comp_bw %>%
  run_cv(comp_dist = comp_dist, cv_grid = blocks_bw)

focal_vs_comp_bw %>%
  rmse(truth = growth, estimate = growth_hat) %>%
  pull(.estimate)
```


### SCBI

Observe once again that this RMSE is much higher than that for the above SCBI model fit without cross-validation. 

```{r scbi-spatial-cv, eval=FALSE}
focal_vs_comp_scbi <- focal_vs_comp_scbi %>%
  run_cv(comp_dist = comp_dist, cv_grid = blocks_scbi)

focal_vs_comp_scbi %>%
  rmse(truth = growth, estimate = growth_hat) %>%
  pull(.estimate)
```




# Discussion





# Acknowledgments





# References




