---
title: "The `forestecology` R package for modeling interspecies competition between trees"

# to produce blinded version set to 1 and change blinded <- TRUE on line 54 below
blinded: 0

authors: 
- name: Albert Y. Kim 
  thanks: "Albert Y. Kim is Assistant Professor, Statistical & Data Sciences, Smith College, Northampton, MA 01063 (e-mail: akim04@smith.edu)."
  affiliation: Program in Statistical & Data Sciences, Smith College
  
- name: David Allen
  affiliation: Biology Department, Middlebury College
  
- name: Simon P. Couch
  affiliation: Mathematics Department, Reed College

abstract: 
- "Move abstract below here after completed."

keywords:
- forest ecology, competition, R, Rstats, tidyverse, sf, cross-validation, 

bibliography: paper.bib
output: rticles::asa_article
link-citations: yes
header-includes:
- \usepackage{xcolor, soul, xspace, float, subfig, lineno}
---

\linenumbers

```{r setup, include = FALSE, cache = FALSE}
# Internally used packages
library(viridis)
library(knitr)
library(ggplot2)
library(here)

# knitr settings
opts_chunk$set(
  # Code output:
  warning = FALSE,
  message = FALSE,
  echo = TRUE,
  cache = TRUE,
  # Figure:
  out.width = "100%",
  fig.path = "Figures/",
  fig.width = 16 / 2.5,
  fig.height = 9 / 2.5,
  fig.align = "center",
  fig.show = "hold",
  # Etc:
  collapse = TRUE,
  comment = "##"
  # tidy = FALSE
)

# Random number generator seed value
set.seed(76)

# Set ggplot defaults output:
if (!is_html_output()) {
  # Grey theme:
  ggplot2::theme_set(theme_light())
  # Color scheme
  scale_colour_discrete <- scale_colour_viridis_d
}

# Set output width
options(width = 70)
```

# Abstract (350 words) {-}

1. When modeling growth of trees forest ecologists often incorporate the effect of interspecies competition. Many such models are based on a neighborhood effect assumption whereby all trees within a fixed distance of all focal trees are considered competitors. Methods are needed to evaluate the effect of interspecies competition and to assess their quality. 
1. We present the `forestecology` package providing methods for both 1) evaluating the out-of-sample performance of our model using spatial-crossvaliation and 2) testing a null hypothesis of of no impact of competitor species' identity on the growth of trees using a permutation test. We implement a class and methods using R's S3 object-oriented system, for a specific linear, Bayesian neighborhood competition model of tree growth. 
1. We demonstrate the package's functions using data from the Smithsonian Conservation Biology Institute's large forest dynamics plot, part of the ForestGEO network of reseach sites. Given ForestGEO's data collection protocols and data formatting standards, the package cross-compatibility of code. We show both that 1) competitor species identity matters and 2) that not spatially cross-validating leads to error estimates that are overly optimistic. 
1. The package follows `tidyverse`-like structure whereby verb-named functions can be modularly "piped" in sequence to intuitively display the sequence of steps of analysis from start to finish. Additionally, most inputs/outputs of functions assume an are of `sf` class from the simple features package, thereby facilitating all wrangling and visualization of geospatial data. Lastly, even though our package is currently limited to one specific model, the package is setup such that it can be easily extended to other models. 




# Introduction

Repeat-censused forest plots offer excellent data to test neighborhood models of tree competition @allen_permutation_2020 @canham_neighborhood_2006 @uriarte_spatially_2004. Here we describe an R package, `forestecology`, to do that. This package implements the methods in @allen_permutation_2020. It provides: a convenient way to specify and fit models of tree growth based on neighborhood competition; a spatial cross validation method to test and compare model fits @roberts_cross-validation_2017; and an ANOVA-like method to assess whether the competitor identity matters in these models. The model is written to work with ForestGEO plot data @andersonteixeira_ctfs-forestgeo_2015, but we envision that it could easily be modified to work with data from other forest plots, e.g. the US Forest Service Forest Inventory and Analysis plots @smith_forest_2002.



The `forestecology` is designed with "tidy" data principles in mind as @wickham_welcome_2019.

Given that our data is of geo-spatial nature, we represent our data using the "simple features" `sf` package class of objects @pebesma_simple_2018 whereby. While previously the `sp` package serves such purposes @pebesma_sp_2005, the `sf` package is designed to interface with the `tidyverse` suite of packages.




# Example

We demonstrate the `forestecology` package's features on the Smithsonian Conservation Biology Institute (SCBI) large forest dynamics plot, located at the Smithsonian's National Zoo and Conservation Biology Institute in Front Royal, VA, USA. The 25.6 ha (640 x 400 m) plot is located at the intersection of three of the major physiographic provinces of the eastern US: the Blue Ridge, Ridge and Valley, and Piedmont provinces and is adjacent to the northern end of Shenandoah National Park. The forest type is typical mature secondary eastern mixed deciduous forest, with a canopy dominated by tulip poplar (*Liriodendron tulipifera*), oaks (*Quercus* spp.), and hickories (*Carya* spp.), and an understory composed mainly of spicebush (*Lindera benzoin*), paw-paw (*Asimina triloba*), American hornbeam (*Carpinus caroliniana*), and witch hazel (*Hamamelis virginiana*) @bourg_initial_2013. 

A high-level overview of the steps of our analysis pipeline is as follows:

1. Compute the growth of trees based on census data
1. Add spatial information:
    1. Define buffer region trees.
    1. Add spatial cross-validation block information.
1. Compute focal versus competitor tree information.
1. Fit model and make predictions.
1. Additionally: Evaluate model performance using spatial cross-validation.
1. Additionally: Evaluate the effect of competitor species identity using permutation tests.


We load all necessary packages.

```{r load-packages}
library(tidyverse)
library(lubridate)
library(sf)
library(forestecology)
```

## Compute the growth of trees based on census data

The first step in the our analysis sequence is to compute the growth of trees using data from two censuses. The `compute_growth()` function computes growth assuming census data that follows ForestGEO standards. Despite such standards, minor variations will still exist between sites thereby necessitating some data wrangling and checking. For example, the SCBI site records all dbh's in millimeters, whereas the Michigan Big Woods site records them in centimeters @andersonteixeira_ctfs-forestgeo_2015 @allen_michigan_2020. The data format of other sites may be such that our `compute_growth()` function doesn't work at all. However, in the end all that matters is that the growth of all trees is saved in a data frame of class `sf` whereby the geolocation of each tree is presented in a `geometry` variable of type `<POINT>` and at a minimum the data contains the following variables: a variable uniquely identifying each tree-stem, `sp` of type `fct` factor identifying species, `dbh1` and `dbh2` of type `dbl` quantifying the dbh at earlier and later census, and `growth` of type `dbl` double quantifying the average annual growth in centimeters. 

We load both 2008 and 2014 SCBI census data `.csv` files as they existed on GitHub on November 20, 2020. After selecting only relevant variables, we perform a few additional data wrangling steps: convert the variable with the date of measurement to be of type `date`, convert dbh to be in centimeters^[A rule of thumb to determine the units of dbh is check if the smallest non-zero and non-missing measurement is 1 or 10. If the former, then centimeters. If the later, then millimeters. This is because ForestGEO protocols state that only trees with dbh greater or equal to 1cm should be included in censuses.], convert the `sp` variable containing species information from type `chr` character to `fct` factor (we will discuss the need for this in Section \ref{spatial-cross-validation}). Furthermore, in order to speed up computation for purposes of this examplt, we only consider a 9 ha subsection of the 25.6 ha of the SCBI site: `gx` from 0--300 instead of 0--400 and `gy` from 300--600 instead of 0--640.

```{r scbi-load-data}
census_2013_scbi <- read_csv("scbi.stem2.csv") %>%
  select(stemID, sp, date = ExactDate, gx, gy, dbh, codes, status) %>%
  mutate(
    date = mdy(date),
    dbh = as.numeric(dbh)/10,
    sp = factor(sp)
  ) %>%
  filter(gx < 300, between(gy, 300, 600))

census_2018_scbi <- read_csv("scbi.stem3.csv") %>%
  select(stemID, sp, date = ExactDate, gx, gy, dbh, codes, status) %>%
  mutate(
    date = mdy(date),
    dbh = as.numeric(dbh)/10,
    sp = factor(sp)
  ) %>%
  filter(gx < 300, between(gy, 300, 600))
```

These two data frames are then used as the two primary arguments to the `compute_growth()` function, along with the `id` argument whereby the user specifies the name of the variable that uniquely identifies each tree-stem under consideration (note this does not include resprouts in the later census):

```{r scbi-compute-growth}
growth_scbi <-
  compute_growth(
    census_1 = census_2013_scbi,
    census_2 = census_2018_scbi %>% filter(!str_detect(codes, "R")),
    id = "stemID"
  )
growth_scbi
```

The output `growth_scbi` is a single data frame of class `sf` that includes a numerical `growth` reflecting the average annual growth in dbh (in cm) for all trees that were alive at both time points as well a `geometry` variable encoding each tree's geolocation. Furthermore, variables that (in theory) remain unchanged between censuses appear only once, such as location variables `gx` and `gy`; as well as species-related variables. Variables that should change between censuses are suffixed with `1` and `2` indicating the earlier and later censuses, such as `dbh1/dbh2` and `codes1/codes2`. 

Given that `growth_scbi` is of class `sf`, it can be easily plotted in `ggplot2` using the `geom_sf()` geometry as seen in Figure \ref{fig:scbi-trees}.

TODO: Rescale points in this plot:

```{r scbi-trees, out.width="66%", fig.cap="Growth of trees at SCBI."}
ggplot() +
  geom_sf(data = growth_scbi, aes(size = growth)) + 
  scale_size(breaks = c(0.01, 0.1, 1), range = c(0.1, 1))
```




## Add spatial information {#spatial-information}

We now encode spatial information to the `growth_df` data frames. First, in order to control for study region edge effects, we add "buffers" to the periphery of the study region (cite Waller?). Our model of interspecific competition relies on a spatial definition of who the competitor trees are for focal trees of interest. Since certain explanatory variables such as basal area are cumulative, we must ensure that all trees being modeled are not biased to have different neighbor structures. This is a particular concern for trees at the boundary of study regions, which will not have the same number of neighbors as trees in the internal part of the study region. 

Second, our ultimate method for model assessment will rely on estimates of model error as generated by cross-validation. Conventional cross-validation schemes assign observations to folds by resampling individual observations at random. However, underlying this scheme is an assumption that the observations are independent. In the case of forest census data, observations exhibit spatial autocorrelation, and thus this dependence must be incorporated in our resampling scheme in spatial cross-validation @roberts_cross-validation_2017 @pohjankukka_estimating_2017 We will therefore associate portions of the study region to spatial folds. 

To these two ends, we define two constants, both of which are in the same units as the `gx` and `gy` variables (most often meters). 

```{r}
comp_dist <- 7.5
cv_fold_size <- 100
```

The first constant is `comp_dist` which defines the maximum distance for a tree's competitive neighborhood. Trees within this distance of each other are assumed to compete while those farther than this distance apart do not. Put differently, all trees within `comp_dist` of a focal tree will be considered its competitors (see below). Other studies have estimated the value of `comp_dist`; we use an average of estimated values @canham_neighborhood_2004, @uriarte_spatially_2004, @tatsumi2013, @canham_neighborhood_2006. 

Furthermore, `comp_dist` will define the size of all buffers considered, which will be encoded as a binary variable `buffer` as computed by the `add_buffer_variable()` function. This function takes as input the main `growth_df` data frame, the `size` of the buffer which we set as `comp_dist`, and the boundary of the study region encoded as a simple features polygon @pebesma_simple_2018. DESCRIBE SF PACKAGE. In the Big Woods example below we will use a pre-loaded simple features polygon while for the SCBI example we present example code on how to manually construct one. 

The second constant is `cv_fold_size` which defines the length and width of the spatial folds (note that for now the spatial folds are restricted be squares). We will then use this constant to associate each observed tree to one of $k$ folds in the respective study region. In the Big Woods example below we will use the `blockCV` R package that has implemented spatial cross-validation while for the SCBI we will do this manually @valavi_blockcv_2019


### Big Woods

First, we indicate which trees are part of the buffer. This necessitates information about the study region boundary. In this case, we use a `sf_polygon` object `study_region_bw` which comes pre-loaded in the `forestecology` packages. After loading `study_region_bw`, we illustrate the results of the `add_buffer_variable()` function in Figure \ref{fig:bw-define-buffer}. Trees on the periphery denote with lighter colors are part of the buffer and will not be considered as "focal" trees of interest going forward; they will only be considered as competitor trees. 

```{r bw-define-buffer, out.width="100%", fig.cap="Buffer region for Big Woods study region."}
data(study_region_bw)

growth_bw <- growth_bw %>%
  add_buffer_variable(direction = "in", size = comp_dist, region = study_region_bw)

ggplot() +
  geom_sf(data = growth_bw %>% sample_frac(0.2), aes(col = buffer), size = 0.5)
```

Second, we associate each tree to spatial cross validation folds. In this case, we use the `spatialBlock()` function from the `blockCV` package to define the spatial grid which 

THIS IS A MESS. We use the  @valavi_blockcv_2019, whose elements will act as the folds in our leave-one-out (by "one" we mean "one grid block") cross-validation scheme. The upshot here is we add `foldID` to `growth_df` which identifies which fold each individual is in, and the creation of a `cv_grid_sf` object which gives the geometry of the cross validation grid.

```{r bw-define-cv-folds, out.width="100%", fig.cap="blockCV function output."}
set.seed(76)
bw_spatialBlock <- spatialBlock(
  speciesData = growth_bw, theRange = cv_fold_size, k = 28, xOffset = 0.5, 
  yOffset = 0, verbose = FALSE, showBlocks = FALSE
)
```

Then add foldID to each tree

```{r}
growth_bw <- growth_bw %>%
  mutate(foldID = bw_spatialBlock$foldID)
```

```{r bw-define-cv-folds-with-trees, out.width="100%", fig.cap="Inspect blocks closely."}
# Visualize grid. Why does fold 19 repeat?
ggplot() +
  geom_sf(data = bw_spatialBlock$blocks %>% st_as_sf()) + 
  geom_sf(data = growth_bw %>% sample_frac(0.2), 
          aes(col = factor(foldID)), size = 0.1, show.legend = FALSE) + 
  geom_sf_text(data = bw_spatialBlock$blocks %>% st_as_sf(), 
               aes(label = folds))
```


Then remove empty folds

```{r}
growth_bw <- growth_bw %>%
  filter(!foldID %in% c(19, 23, 21, 17, 8, 19)) %>%
  mutate(foldID = factor(foldID))
```

Separately, we save the spatial cross-validation grid as an `sf_polygon` object `blocks_bw`

```{r}
blocks_bw <- bw_spatialBlock$blocks %>%
  st_as_sf()
```



### SCBI

First, we indicate which trees are part of the buffer. In this case however we manually define the study region boundary based on the subregion we defined in Section \ref{scbi-data} and create an `sf_polygon` object using the `sf_polygon()` function from the `sfheaders` package. Figure \ref{fig:scbi-define-buffer} displays the resulting buffer trees. 

```{r scbi-define-buffer, out.width="50%", fig.cap="Buffer region for SCBI study region."}
study_region_scbi <- tibble(
  x = c(0, 300, 300, 0, 0),
  y = c(300, 300, 600, 600, 300)
) %>%
  sf_polygon()

growth_scbi <- growth_scbi %>%
  add_buffer_variable(direction = "in", size = comp_dist, region = study_region_scbi)

ggplot() +
  geom_sf(data = growth_scbi, aes(col = buffer), size = 0.5)
```

Second, we associate each tree to spatial cross validation folds. In this case we manually define a spatial crossvaliation grid. Figure \ref{fig:scbi-define-cv-folds} displays the resulting cross-validation folds along with the buffer from Figure \ref{fig:scbi-define-buffer}.

Here we manually define the spatial cross-validation grid as an `sf_polygon` object `scbi_cv_grid`

```{r}
fold1 <- rbind(c(0, 300), c(150, 300), c(150, 600), c(0, 600))
fold2 <- rbind(c(150, 300), c(300, 300), c(300, 600), c(150, 600))

blocks_scbi <- bind_rows(
  sf_polygon(fold1),
  sf_polygon(fold2)
) %>%
  mutate(folds = c(1, 2) %>% factor())
```

```{r scbi-define-cv-folds, out.width="50%", fig.cap="Buffer region for SCBI study region."}
SpatialBlock_scbi <- spatialBlock(
  speciesData = growth_scbi, k = 2, selection = "systematic", blocks = blocks_scbi,
  showBlocks = FALSE, verbose = FALSE
)

# Add foldID to each tree
growth_scbi <- growth_scbi %>%
  mutate(foldID = SpatialBlock_scbi$foldID %>% factor())

ggplot() +
  geom_sf_text(data = growth_scbi, aes(label = foldID, col = buffer)) +
  geom_sf(data = blocks_scbi, fill = "transparent")
```



## Define focal versus competitor trees

Next we define `focal_vs_comp` data frames which connects each focal tree in the `growth_df` data frames to the trees in its competitive neighborhood range as defined by the `comp_dist` constant. So for example, if `growth_df` consisted of two focal trees with two and three neighbors with `comp_dist` respectively, `focal_vs_comp` would be a data frame of 5 rows connecting each focal tree to it's competitors. The `create_focal_vs_comp()` function makes this connection taking as inputs the `growth_df` data frame; the `comp_dist` constant defining competitive range; `cv_grid_sf`, giving the cross validation grid; and the `id` variable.

### Big Woods

```{r bw-focal-vs-comp}
focal_vs_comp_bw <- growth_bw %>%
  create_focal_vs_comp(comp_dist, cv_grid_sf = blocks_bw, id = "treeID")
```

TODO: Figure out how to show this data frame's contents.


### SCBI 

```{r scbi-focal-vs-comp}
focal_vs_comp_scbi <- growth_scbi %>%
  create_focal_vs_comp(comp_dist, cv_grid_sf = blocks_scbi, id = "stemID")
```

TODO: Figure out how to show this data frame's contents.




## Fit model and make predictions {#model-fit-predict}

Next we fit the following linear model to the dbh of each focal tree. Let $i = 1, \ldots, n_j$ index all $n_j$ trees of "focal" species group $j$; let $j = 1, \ldots, J$ index all $J$ focal species groups; and let $k = 1, \ldots, K$ index all $K$ "competitor" species groups. We modeled the growth in diameter per year $y_{ij}$ (in centimeters per year) of the $i^{th}$ tree of focal species group $j$ as a linear model $f$ of the following covariates $\vec{x}_{ij}$

$$
\newcommand{\dbh}{\text{DBH}}
\newcommand{\biomass}{\text{biomass}}
\newcommand{\BA}{\text{BA}}
y_{ij} = f(\vec{x}_{ij}) + \epsilon_{ij} = \beta_{0,j} + \beta_{\dbh,j} \cdot \dbh_{ij} + \sum_{k=1}^{K} \lambda_{jk} \cdot \BA_{ijk} + \epsilon_{ij}
$$

<!--where $\beta_{0,j}$ is the diameter-independent growth rate for group $j$; $\dbh_{ij}$ is the diameter at breast height (in centimeters) of the focal tree at the earlier census; $\beta_{\dbh,j}$ is the amount of the growth rate changed depending on diameter for group $j$;  $\BA_{ijk}$ is the sum of the basal area of all trees of competitor species group $k$; $\lambda_{jk}$ is the change in growth for individuals of group $j$ from nearby competitors of group $k$; and $\epsilon_{ij}$ is a random error term distributed $\text{Normal}(0, \sigma^2)$.-->

We estimate the model's parameters using Bayesian linear regression implemented in the `fit_bayesian_model()` function. TODO: define all parameters

For this linear model's case, there exists a closed form solution as described here. As such, the `fit_bayesian_model()` function using matrix algebra to obtain all parameter estimates, rather than computationally expensive Monte Carlo approximations. The inputs to this function are a `focal_vs_comp` data frame, `prior_param` a list of priors, and a boolean flag `run_shuffle` on whether or not to run competitor-species identity permutations which we will demonstrate below on the Michigan Big Woods data. This function returns the posterior means of all parameters.

Using these posterior means, we then use the posterior predictive distribution to obtain fitted/predicted values $\widehat{y}$ of the dbh for each focal tree using the `predict_bayesian_model()`. These $\widehat{y}$ can then be compared to the observed $y$ dbh's to compute the root mean-square error, a measure of a model's predictive error which has the same units as the observed data $y$.

### Big Woods 

For the Michigan Big Woods data we present two use cases of the model fitting and prediction scheme. The first use case is the simplest where we assess the fit of the model using root mean squared error. The second use case then answers the question of whether species competitor identity matters using permutation test. 

For the first use case, we fit the linear model specified in Equation XXX to our data frame of type `focal_vs_comp`. This input/outputs of the `fit_bayesian_model()` function are lists of the prior/posterior means of parameters of the linear regression specified in XXX. Generally speaking, there are two classes of regression parameters: $\beta$ main effects and $\lambda$ competitive effects. In the upcoming Section \ref{viz-posterior-distributions}, we will present code visualizing this posterior distributions.

```{r bw-model-fit}
comp_bayes_lm_bw <- focal_vs_comp_bw %>%
  comp_bayes_lm(prior_param = NULL)
```

This output of posterior parameters for the specified competition model are then used along with the posterior predictive distribution encoded in `predict_bayesian_model()` to return predicted growths for each individual tree. We join these predicted growths to the original growth data frame. 

```{r bw-model-predict}
focal_vs_comp_bw <- focal_vs_comp_bw %>%
  mutate(growth_hat = predict(comp_bayes_lm_bw, focal_vs_comp_bw))
```

We then use the `rmse()` function from the `yardstick` package to obtain the root mean squared error of the observed versus fitted values of growth. 

```{r bw-model-rmse}
focal_vs_comp_bw %>%
  rmse(truth = growth, estimate = growth_hat) %>%
  pull(.estimate)
```

The second use case is near identical to the first, but with a small change in the code to test whether the identity of the competitor matters. By adding a `run_shuffle = TRUE` argument to `fit_bayesian_model()`, for each focal tree its competitor trees' species identity will be "shuffled" randomly much like in a permutation test. By shuffling these species labels we are effectively fitting the model under a null model that competitor species identity does not matter. If the "shuffled" RMSE's are consistently lower than the unshuffled RMSE corresponding to the observed data, then we have evidence to suggest that competitor identity matters to competitive interactions.

```{r bw-model-shuffle-fit}
comp_bayes_lm_bw_shuffle <- focal_vs_comp_bw %>%
  comp_bayes_lm(prior_param = NULL, run_shuffle = TRUE)
```

```{r bw-model-shuffle-predict}
focal_vs_comp_bw <- focal_vs_comp_bw %>%
  mutate(growth_hat_shuffle = predict(comp_bayes_lm_bw_shuffle, focal_vs_comp_bw))
```

```{r bw-model-shuffle-rmse}
focal_vs_comp_bw %>%
  rmse(truth = growth, estimate = growth_hat_shuffle) %>%
  pull(.estimate)
```

The RMSE is fact lower for the non-shuffled version, indicative of a better model fit. This gives support for the idea that competitor identity does matter for competitive interactions. In @allen_permutation_2020 we run this shuffle a large number of times to construct a full permutation distribution to show that this difference is robust to resampling variation.

### SCBI 

In the case of the SCBI data, we once again perform the same model fitting and computing of fitted growths as with the Big Woods data, but this time we map the residuals of the observed minus fitted values to look for spatial patterns. 

```{r scbi-model-fit}
comp_bayes_lm_scbi <- focal_vs_comp_scbi %>%
  comp_bayes_lm(prior_param = NULL)
```

```{r scbi-model-predict}
focal_vs_comp_scbi <- focal_vs_comp_scbi %>%
  mutate(growth_hat = predict(comp_bayes_lm_scbi, focal_vs_comp_scbi))
```

```{r scbi-model-rmse}
focal_vs_comp_scbi %>%
  rmse(truth = growth, estimate = growth_hat) %>%
  pull(.estimate)
```

In Figures \ref{fig:scbi-model-residuals} and \ref{fig:scbi-model-residuals-2} we present the residuals. 

```{r scbi-model-residuals, out.width="100%", fig.cap="Predicted versus observed growth.", echo = FALSE}
ggplot(focal_vs_comp_scbi, aes(x = growth, y = growth_hat)) +
  geom_point(size = 0.5, color = rgb(0, 0, 0, 0.25)) +
  stat_smooth(method = "lm") +
  geom_abline(slope = 1, intercept = 0) +
  coord_fixed() +
  labs(
    x = "Observed growth in dbh", y = "Predicted growth in dbh",
    title = "Predicted vs Observed Growth"
  )
```

```{r scbi-model-residuals-2, out.width="80%", fig.cap="Spatial distribution of residuals for model applied to SCBI data.", echo = FALSE}
focal_vs_comp_scbi %>%
  st_as_sf() %>%
  # TODO: Need to investigate missingness
  filter(!is.na(growth_hat)) %>%
  mutate(
    error = growth - growth_hat,
    error_bin = cut_number(error, n = 5),
    error_compress = ifelse(error < -0.75, -0.75, ifelse(error > 0.75, 0.75, error))
  ) %>%
  ggplot() +
  geom_sf(aes(col = error_compress), size = 1) +
  theme_bw() +
  scale_color_gradient2(
    low = "#ef8a62", mid = "#f7f7f7", high = "#67a9cf",
    name = expression(paste("Residual (cm ", y^{-1}, ")")),
    breaks = seq(from = -0.75, to = 0.75, by = 0.25),
    labels = c("< -0.75", "-0.5", "0.25", "0", "0.25", "0.5", "> 0.75")
  ) +
  labs(x = "Meter", y = "Meter")
```


## Run spatial cross-validation {#spatial-cross-validation}

The model fits and predictions in Section \ref{model-fit-predict} all suffer from a common failing: they use the same data to both fit the model and to assess the model's performance using the RMSE. As argued by @roberts_cross-validation_2017, this can lead to overly optimistic assessments of model quality as the models can be overfit, in particular in situations where spatial-autocorrelation is present. To mitigate the effects of such overfitting, we use a spatially block cross-validation algorithm implemented in the `run_cv()`. This function at its core uses the same model fitting implemented in the `fit_bayesian_model()` function, however trains the model on $k-1$ spatial folds of the train and returns fitted values for the test data. Recall that the spatial blocking scheme wass encoded in Section \ref{spatial-information}.

### Big Woods

Applying this spatially cross-validated model fit yields an RMSE is higher than that when the model is fit without cross validation. In other words, our model fits in \ref{model-fit-predict} were overly optimistic in the model's fitting power, whereas a cross-validated results yield an estimate that is closer to the truth. See @allen_permutation_2020 for more discussion of this. 

```{r bw-spatial-cv}
focal_vs_comp_bw <- focal_vs_comp_bw %>%
  run_cv(comp_dist = comp_dist, cv_grid = blocks_bw)

focal_vs_comp_bw %>%
  rmse(truth = growth, estimate = growth_hat) %>%
  pull(.estimate)
```


### SCBI

Observe once again that this RMSE is much higher than that for the above SCBI model fit without cross-validation. 

```{r scbi-spatial-cv}
focal_vs_comp_scbi <- focal_vs_comp_scbi %>%
  run_cv(comp_dist = comp_dist, cv_grid = blocks_scbi)

focal_vs_comp_scbi %>%
  rmse(truth = growth, estimate = growth_hat) %>%
  pull(.estimate)
```




## Visualize posterior distributions {#viz-posterior-distributions}

Lastly, we return to the model fits from Section \ref{model-fit-predict} and present tools to visually explore the posterior distributions of all parameters in our model. There are two main groups of parameters to consider. The $\beta$ coefficients tell us about how fast each species grows and how this depends on DBH while the full matrix of $\lambda$ values describe the competitive effects between pairs of species. There is a rich literature on this matrix (cite). 

DO WE NEED TO DESCRIBE MECHANICS? Because of the structure of the `bw_fit_model` object we cannot simply draw these curves based on the posterior distribution. `bw_fit_model()` gives the parameters *compared* to a baseline. This is not of direct interest. So to display these parameters, as we care about them, we have to sample from the baseline distribution and from the comparison one to get the posterior distribution of interest. 


### Big Woods 

Here we re-run the model fit to the Big Woods data from Section \ref{model-fit-predict}, but this time use "family" as the group for comparison which has. This makes the posterior distributions easier to follow. Also, surprisingly, grouping by family performed just as well as grouping by species @allen_permutation_2020. First we re-run `create_focal_vs_comp()` and `fit_bayesian_model()` with no permutation shuffling with the grouping variable as family.

```{r bw-posterior-viz-0}
focal_vs_comp_bw <- growth_bw %>%
  mutate(sp = family %>% factor()) %>%
  create_focal_vs_comp(comp_dist = comp_dist, cv_grid_sf = blocks_bw, id = "treeID")

comp_bayes_lm_bw <- focal_vs_comp_bw %>%
  comp_bayes_lm(prior_param = NULL)
```

Now the posterior parameter outputs of `fit_bayesian_model()` are passed to `plot_bayesian_model_parameters()` to generate visualizations of the posterior parameters. These visualizations are displayed in Figure 5 of @allen_permutation_2020. For simplicity we only plot a subset of the species families. 

```{r bw-posterior-viz-1}
sp_to_plot <- c("cornaceae", "fagaceae", "hamamelidaceae", "juglandaceae", 
                 "lauraceae", "rosaceae", "sapindaceae", "ulmaceae")
```

The output is a list with three plots stored. Figure \ref{fig:bw-posterior-viz-beta0} The element `beta_0` gives the baseline growth intercept $\beta_0$, i.e., how fast an individual of each group grows independent of DBH).

```{r bw-posterior-viz-beta0, out.width="100%", fig.cap="Posterior distribution of beta0."}
plot1 <- autoplot(comp_bayes_lm_bw, type = "intercepts")
plot1
```

Figure \ref{fig:bw-posterior-viz-beta-dbh} Next `beta_dbh` gives the slope for DBH slope $\beta_{dbh,i}$ for each group.

```{r bw-posterior-viz-beta-dbh, out.width="100%", fig.cap="Posterior distribution of betadbh."}
plot2 <- autoplot(comp_bayes_lm_bw, type = "dbh_slopes")
plot2
```

Finally Figure \ref{fig:bw-posterior-viz-lambda} `lambda` gives the competition coefficients $\lambda$.

```{r bw-posterior-viz-lambda, out.width="100%", fig.cap="Posterior distribution of lambda's for Big Woods."}
plot3 <- autoplot(comp_bayes_lm_bw, type = "competition")
plot3
```


### SCBI

We revisit the posterior parameters for the SCBI from Section {model-fit-predict}, but this time only focus on the $\lambda$ competition coefficients. 

```{r scbi-posterior-viz-1}
sp_to_plot <- c("quru", "litu", "cagl", "cato")
```

```{r scbi-posterior-viz-lambda, out.width="100%", fig.cap="Posterior distribution of lambda's for SCBI."}
plot3 <- autoplot(comp_bayes_lm_bw, type = "competition")
plot3
```

Add explanation here. 

HEY BERT PICK IT UP HERE



# Discussion





# Acknowledgments





# References




