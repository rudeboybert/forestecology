---
title: "`forestecology` package for modeling interspecies competition between trees"

# to produce blinded version set to 1 and change blinded <- TRUE on line 54 below
blinded: 0

authors: 
- name: Albert Y. Kim 
  thanks: "Albert Y. Kim is Assistant Professor, Statistical & Data Sciences, Smith College, Northampton, MA 01063 (e-mail: akim04@smith.edu)."
  affiliation: Program in Statistical & Data Sciences, Smith College
  
- name: David Allen
  affiliation: Biology Department, Middlebury College

abstract: 
- "Move abstract below here after completed."

keywords:
- forest ecology, competition, R, Rstats, tidyverse, sf, cross-validation, 

bibliography: paper.bib
output: rticles::asa_article
link-citations: yes
header-includes:
- \usepackage{xcolor, soul, xspace, float, subfig, lineno}
---

\linenumbers

```{r setup, include = FALSE, cache = FALSE}
# knitr settings
knitr::opts_chunk$set(
  # Code output:
  warning = FALSE,
  message = FALSE,
  echo = TRUE,
  cache = TRUE,
  # Figure:
  out.width = "100%",
  fig.path = "Figures/",
  fig.width = 16 / 2.5,
  fig.height = 9 / 2.5,
  fig.align = "center",
  fig.show = "hold",
  # Etc:
  collapse = TRUE,
  comment = "##"
  # tidy = FALSE
)

# Internally used packages
library(knitr)
library(ggplot2)
library(viridis)

# Random number generator seed value
set.seed(76)

# Set ggplot defaults output:
if (!knitr::is_html_output()) {
  # Grey theme:
  theme_set(theme_light())
  # Color scheme
  # TODO: REVERT THIS
  # scale_colour_discrete <- scale_colour_viridis_d
}

# Set output width
options(width = 70)
```

# Abstract (350 words)

1. Set the context for and purpose of the work: The scientific question/problem and the desiderata
    + (Eventually) modularly fitting models for interspecific competition and assessing them using spatial crossvalidation
    + Leverage ForestGEO protocols providing standardization
1. Indicate the approach and the methods: Use tidyverse, simple features, and tidymodels packages. 
    + tidyverse: as stated in tidy tools manifesto: standadized data structures, functional programming with pipe, designed for humans
    + sf: tidyverse-friendly package that makes wrangling and visualizing spatial data much easier
    + tidymodels: given our spatial-crossvalidation, use tidymodels framework is a collection of packages for modeling and machine learning using tidyverse principles
1. Outline the main results: We replicate from scratch the figure in PLOSOne paper using Big Woods data, conduct similar analysis for SCBI data.
    + Code would've been way more complicated in base. 
    + We don't have to worry about how the component functions work, only that sequence/converyor belt is correct and output is correct.
    + Scientist is abstracted away from ugly programming details.
1. Identify the conclusions and wider implications:
    + New scientific conclusions from SCBI data
    + Modularly switch out our bayesian lm() functions to anything you want.
    + this can serve as blue print for other modeling situations.

# Introduction

Repeat-censused forest plots offer excellent data to test neighborhood models of tree competition @allen_permutation_2020 @canham_neighborhood_2006 @uriarte_spatially_2004. Here we describe an R package, `forestecology`, to do that. This package implements the methods in @allen_permutation_2020. It provides: a convenient way specify and fit models of tree growth based on neighborhood competition; a spatial cross validation method to test and compare model fits @roberts_cross-validation_2017; and an ANOVA-like method to assess whether the competitor identity matters in these models. The model is written to work with ForestGEO plot data @andersonteixeira_ctfs-forestgeo_2015, but we envision that it could easily be modified to work with data from other forest plots, e.g. the US Forest Service Forest Inventory and Analysis plots @smith_forest_2002.


# Example

We demonstrate the `forestecology` package's features on two data sets, both based on inventory censuses of two sites from the Smithsonian Institution’s ForestGEO international network of 72 long‐term forest dynamics research sites @andersonteixeira_ctfs-forestgeo_2015. First, the Michigan Big Woods Forest Dynamics Plot located at the Edwin S. George Reserve in Pinckney, MI, USA. The 23 ha plot is situated in mature oak-hickory forest. The canopy is dominated by white oak (Quercus alba), northern red oak (Quercus rubra), black oak (Quercus velutina), shagbark hickory (Carya ovata) and pignut hickory (Carya glabra). The most common understory tree is witch-hazel (Hamamelis virginiana) @allen_michigan_2020. In the example below, we will preface any data frames from this plot in with `bw_`.

Second, the Smithsonian Conservation Biology Institute (SCBI) large forest dynamics plot, located at the Smithsonian's National Zoo and Conservation Biology Institute in Front Royal, VA, USA. The 25.6 ha (640 x 400 m) plot is located at the intersection of three of the major physiographic provinces of the eastern US: the Blue Ridge, Ridge and Valley, and Piedmont provinces and is adjacent to the northern end of Shenandoah National Park. The forest type is typical mature secondary eastern mixed deciduous forest, with a canopy dominated by tulip poplar (Liriodendron tulipifera), oaks (Quercus spp.), and hickories (Carya spp.), and an understory composed mainly of spicebush (Lindera benzoin), paw-paw (Asimina triloba), American hornbeam (Carpinus caroliniana), and witch hazel (Hamamelis virginiana) @bourg_initial_2013. In the example below, we will preface any data frames from this plot in with `scbi_`.

The code that generates Figures are included in the supplementary materials. 


We load all the necessary packages.

```{r load-packages}
library(forestecology)

# Load tidyverse packages:
library(tidyverse)
library(lubridate)

# Load spatial packages:
library(blockCV)
library(sf)
library(sfheaders)

# Load other packages:
library(snakecase)
library(yardstick)
```

## Preprocess census data 

We start by preprocessing the census data for both sites. While ForestGEO data protocols ensure a high degree of standardization between site, minor variations still exist @andersonteixeira_ctfs-forestgeo_2015. While the Big Woods data comes pre-loaded in the `forestecology` package, we load the SCBI data as they are saved in .csv files in the SCBI-ForestGEO-Data repository on GitHub @gonzalez-akre_scbi-forestgeoscbi-forestgeo-data_2020.  In both cases, we load the census data as R as "tibble" data frames thereby ensuring a standardized input/output format that can be used across all `tidyverse` packages @wickham_welcome_2019. 

Furthermore, we ensure that the different variables have the correct names, types (`dbl`, `data`, `factor`). 

### Big Woods

We load census data from 2008 and 2014 saved in the package, then merge species data (genus, species, linnean classification, family, etc). 

```{r bw-load-data}
data(bw_census_2008, bw_census_2014, bw_species)

# Append additional species data
bw_census_2008 <- bw_census_2008 %>%
  left_join(bw_species, by = "sp") %>%
  select(-c(genus, species, latin))
```

### SCBI {#scbi-data}

We load census data from 2008 and 2014 from `.csv` files saved from GitHub on November 20, 2020. Furthermore, we perform two additional pre-processing steps. First, in order to speed up computation for purposes of this example, we only consider a 9 ha subsection of the 25.6 ha of the SCBI site: `gx` from 0--300 instead of 0--400 and `gy` from  300--600 instead of 0--640. Second, in order to standardize comparisons between Big Woods and SCBI, we convert the units of dbh from mm to cm. ^[A rule of thumb to ascertain if dbh is in mm or cm is to verify if the smallest non-zero and non-missing measurement is 1 or 10. If the former, then cm. If the later, then mm. This is because ForestGEO protocols state that only trees with dbh greater or equal to 1cm should be included in censuses. ]

```{r scbi-load-data}
scbi_2013 <- read_csv("scbi.stem2.csv") %>%
  select(treeID, stemID, sp, ExactDate, gx, gy, dbh, codes, status) %>%
  mutate(
    date = ExactDate,
    dbh = as.numeric(dbh),
    date = mdy(date)
  ) %>%
  filter(gx < 300, between(gy, 300, 600)) %>% 
  mutate(dbh = dbh / 10)

scbi_2018 <- read_csv("scbi.stem3.csv") %>%
  select(treeID, stemID, sp, ExactDate, gx, gy, dbh, codes, status) %>%
  mutate(
    date = ExactDate,
    dbh = as.numeric(dbh),
    date = mdy(date)
  ) %>%
  filter(gx < 300, between(gy, 300, 600)) %>% 
  mutate(dbh = dbh / 10)
```



## Compute annual growth

For each plot we then compute average annual growth between the two censuses using the `compute_growth()` function. This function takes the two census data frames as well as a character indicating which variable in both data frames uniquely identifies each stem. This function returns a single data frame that includes a numerical variable `growth` reflecting the average annual dbh growth (in cm) of all trees alive at both time points. Furthermore, variables that (in theory) remain unchanged between censuses appear only once, such as location variables `gx` and `gy`; as well as species-related variables. Variables that should change between censuses are suffixed with `1` and `2` indicating the earlier and later censuses, such as `dbh1/dbh2` and `codes1/codes2`. Here the resulting data frames are named with some variation of `growth_df`.

After computing the average annual growth for each tree, we ensure to convert all variables denote species from type character to factors; this is to ensure that issues of rare species being accounted for in both training and test sets in our upcoming cross-validation step (see Section REF)

### Big Woods

In the case of Big Woods data, we first remove all trees that were re-sprouts in the later (2014) census. Additionally, we have included three classification of tree species: `species`, `family`, and `trait_group`. DESCRIBE THESE

```{r bw-compute-growth}
bw_census_2014 <- bw_census_2014 %>%
  filter(!str_detect(codes, "R"))

bw_growth_df <-
  compute_growth(bw_census_2008, bw_census_2014, id = "treeID") %>%
  # Convert all variables denoting species to factors
  mutate(
    sp = sp %>% to_any_case() %>% as.factor(),
    species = sp,
    family = as.factor(family),
    trait_group = as.factor(trait_group)
  ) %>%
  # Drop unnecessary variables
  select(-stemID)
```

### SCBI

```{r scbi-compute-growth}
scbi_growth_df <-
  compute_growth(scbi_2013, scbi_2018, "stemID") %>%
  # Convert all variables denoting species to factors
  mutate(sp = as.factor(sp))
```

### Comparison

Figure \ref{fig:growth-histogram} displays histograms comparing the distribution of average annual growth at both sites. Observe that average annual growth appears higher at the Big Woods site.

```{r growth-histogram, out.width="100%", fig.cap="Distribution of average annual growth in DBH for both sites.", echo = FALSE}
# Both Big Woods & SCBI
bind_rows(
  bw_growth_df %>% st_drop_geometry() %>% select(growth) %>% mutate(Site = "Big Woods"),
  scbi_growth_df %>% st_drop_geometry() %>% select(growth) %>% mutate(Site = "SCBI")
) %>% 
  ggplot(aes(x = growth, y = ..density.., fill = Site)) +
  geom_histogram(alpha = 0.5, position = "identity", binwidth = 0.05) +
  labs(x = "Average annual growth in dbh (cm per yr)") +
  coord_cartesian(xlim = c(-0.5, 1))
```



## Add spatial information {#spatial-information}

We now encode spatial information to the `growth_df` data frames. First, in order to control for study region edge effects, we add "buffers" to the periphery of the study region (cite Waller?). Our model of interspecific competition relies on a spatial definition of who the competitor trees are for focal trees of interest. Since certain explanatory variables such as biomass are cumulative, we must ensure that all trees being modeled are not biased to have different neighbor structures. This is a particular concern for trees at the boundary of study regions, which will not have the same number of neighbors as trees in the internal part of the study region. 

Second, our ultimate method for model assessment will rely on estimates of model error as generated by cross-validation. Conventional cross-validation schemes assign observations to folds by resampling individual observations at random. However, underlying this scheme is an assumption that the observations are independent. In the case of forest census data, observations exhibit spatial autocorrelation, and thus this dependence must be incorporated in our resampling scheme in spatial cross-validation @roberts2017 @pohjankukka2017. We will therefore associate portions of the study region to spatial folds. 

To these two ends, we define two constants, both of which are in the same units as the `gx` and `gy` variables (most often meters). 

```{r}
max_dist <- 7.5
cv_fold_size <- 100
```

The first constant is `max_dist` which defines the maximum distance for a tree's competitive neighborhood. Trees within this distance of each other are assumed to compete while those farther than this distance apart do not. Put differently, all trees within `max_dist` of a focal tree will be considered its competitors (see below). Other studies have estimated the value of `max_dist`; we use an average of estimated values @canham_neighborhood_2004, @uriarte_spatially_2004, @tatsumi2013, @canham_neighborhood_2006. 

Furthermore, `max_dist` will define the size of all buffers considered, which will be encoded as a binary variable `buffer` as computed by the `add_buffer_variable()` function. This function takes as input the main `growth_df` data frame, the `size` of the buffer which we set as `max_dist`, and the boundary of the study region encoded as a simple features polygon @pebesma_simple_2018. DESCRIBE SF PACKAGE. In the Big Woods example below we will use a pre-loaded simple features polygon while for the SCBI example we present example code on how to manually construct one. 

The second constant is `cv_fold_size` which defines the length and width of the spatial folds (note that for now the spatial folds are restricted be squares). We will then use this constant to associate each observed tree to one of $k$ folds in the respective study region. In the Big Woods example below we will use the `blockCV` R package that has implemented spatial cross-validation while for the SCBI we will do this manually @valavi2019.


### Big Woods

First, we indicate which trees are part of the buffer. This necessitates information about the study region boundary. In this case, we use a `sf_polygon` object `bw_study_region` which comes pre-loaded in the `forestecology` packages. After loading `bw_study_region`, we illustrate the results of the `add_buffer_variable()` function in Figure \ref{fig:bw-define-buffer}. Trees on the periphery denote with lighter colors are part of the buffer and will not be considered as "focal" trees of interest going forward; they will only be considered as competitor trees. 

```{r bw-define-buffer, out.width="100%", fig.cap="Buffer region for Big Woods study region."}
data(bw_study_region)

bw_growth_df <- bw_growth_df %>%
  add_buffer_variable(direction = "in", size = max_dist, 
                      region = bw_study_region)

ggplot() +
  geom_sf(data = bw_growth_df %>% sample_frac(0.2), 
          aes(col = buffer), size = 0.5)
```

Second, we associate each tree to spatial cross validation folds. In this case, we use the `spatialBlock()` function from the `blockCV` package to define the spatial grid which 

THIS IS A MESS. We use the  @valavi_blockcv_2019, whose elements will act as the folds in our leave-one-out (by "one" we mean "one grid block") cross-validation scheme. The upshot here is we add `foldID` to `growth_df` which identifies which fold each individual is in, and the creation of a `cv_grid_sf` object which gives the geometry of the cross validation grid.

```{r bw-define-cv-folds, out.width="100%", fig.cap="blockCV function output."}
set.seed(76)
bw_spatialBlock <- spatialBlock(
  speciesData = bw_growth_df, theRange = cv_fold_size, k = 28, xOffset = 0.5, 
  yOffset = 0, verbose = FALSE, showBlocks = FALSE
)
```

# Add foldID to each tree
```{r}
bw_growth_df <- bw_growth_df %>%
  mutate(foldID = bw_spatialBlock$foldID)
```

```{r bw-define-cv-folds-with-trees, out.width="100%", fig.cap="Inspect blocks closely."}
# Visualize grid. Why does fold 19 repeat?
ggplot() +
  geom_sf(data = bw_spatialBlock$blocks %>% st_as_sf()) + 
  geom_sf(data = bw_growth_df %>% sample_frac(0.2), 
          aes(col = factor(foldID)), size = 0.1, show.legend = FALSE) + 
  geom_sf_text(data = bw_spatialBlock$blocks %>% st_as_sf(), 
               aes(label = folds))
```


# Remove empty folds

```{r}
bw_growth_df <- bw_growth_df %>%
  filter(!foldID %in% c(19, 23, 21, 17, 8, 19)) %>%
  mutate(foldID = as.character(foldID))
```

Separately, we save the spatial cross-validation grid as an `sf_polygon` object `bw_cv_grid`

```{r}
bw_cv_grid <- bw_spatialBlock$blocks %>%
  st_as_sf()
```



### SCBI

First, we indicate which trees are part of the buffer. In this case however we manually define the study region boundary based on the subregion we defined in Section \ref{scbi-data} and create an `sf_polygon` object using the `sf_polygon()` function from the `sfheaders` package. Figure \ref{fig:scbi-define-buffer} displays the resulting buffer trees. 

```{r scbi-define-buffer, out.width="50%", fig.cap="Buffer region for SCBI study region."}
scbi_study_region <- tibble(
  x = c(0, 300, 300, 0, 0),
  y = c(300, 300, 600, 600, 300)
) %>%
  sf_polygon()

scbi_growth_df <- scbi_growth_df %>%
  add_buffer_variable(direction = "in", size = max_dist, 
                      region = scbi_study_region)

ggplot() +
  geom_sf(data = scbi_growth_df, aes(col = buffer), size = 0.5)
```

Second, we associate each tree to spatial cross validation folds. In this case we manually define a spatial crossvaliation grid. Figure \ref{fig:scbi-define-cv-folds} displays the resulting cross-validation folds along with the buffer from Figure \ref{fig:scbi-define-buffer}.

Here we manually define the spatial cross-validation grid as an `sf_polygon` object `scbi_cv_grid`

```{r}
fold1 <- rbind(c(0, 300), c(150, 300), c(150, 600), c(0, 600)) %>%
  sf_polygon() %>% 
  mutate(folds = 1)
fold2 <- rbind(c(150, 300), c(300, 300), c(300, 600), c(150, 600)) %>%
  sf_polygon() %>% 
  mutate(folds = 2)
scbi_cv_grid <- bind_rows(fold1, fold2)
```

```{r scbi-define-cv-folds, out.width="50%", fig.cap="Buffer region for SCBI study region."}
scbi_spatialBlock <- spatialBlock(
  speciesData = scbi_growth_df, k = 2, verbose = FALSE, showBlocks = FALSE,
  # Note new arguments:
  selection = "systematic", blocks = scbi_cv_grid
)

# Add foldID to each tree
scbi_growth_df <- scbi_growth_df %>%
  mutate(foldID = scbi_spatialBlock$foldID)

ggplot() +
  geom_sf_text(data = scbi_growth_df, 
               aes(label = foldID, col = buffer)) +
  geom_sf(data = scbi_cv_grid, fill = "transparent")
```



## Define focal versus competitor trees

Next we define `focal_vs_comp` data frames which connects each focal tree in the `growth_df` data frames to the trees in its competitive neighborhood range as defined by the `max_dist` constant. So for example, if `growth_df` consisted of two focal trees with two and three neighbors with `max_dist` respectively, `focal_vs_comp` would be a data frame of 5 rows connecting each focal tree to it's competitors. The `create_focal_vs_comp()` function makes this connection taking as inputs the `growth_df` data frame; the `max_dist` constant defining competitive range; `cv_grid_sf`, giving the cross validation grid; and the `id` variable.

### Big Woods

```{r bw-focal-vs-comp}
focal_vs_comp_bw <- bw_growth_df %>%
  create_focal_vs_comp(max_dist, cv_grid_sf = bw_cv_grid, id = "treeID")
```

TODO: Figure out how to show this data frame's contents.


### SCBI 

```{r scbi-focal-vs-comp}
focal_vs_comp_scbi <- scbi_growth_df %>%
  create_focal_vs_comp(max_dist, cv_grid_sf = scbi_cv_grid, id = "stemID")
```

TODO: Figure out how to show this data frame's contents.




## Fit model and make predictions {#model-fit-predict}

Next we fit the following linear model to the dbh of each focal tree. Let $i = 1, \ldots, n_j$ index all $n_j$ trees of "focal" species group $j$; let $j = 1, \ldots, J$ index all $J$ focal species groups; and let $k = 1, \ldots, K$ index all $K$ "competitor" species groups. We modeled the growth in diameter per year $y_{ij}$ (in centimeters per year) of the $i^{th}$ tree of focal species group $j$ as a linear model $f$ of the following covariates $\vec{x}_{ij}$

$$
\newcommand{\dbh}{\text{DBH}}
\newcommand{\biomass}{\text{biomass}}
\newcommand{\BA}{\text{BA}}
y_{ij} = f(\vec{x}_{ij}) + \epsilon_{ij} = \beta_{0,j} + \beta_{\dbh,j} \cdot \dbh_{ij} + \sum_{k=1}^{K} \lambda_{jk} \cdot \BA_{ijk} + \epsilon_{ij}
$$

<!--where $\beta_{0,j}$ is the diameter-independent growth rate for group $j$; $\dbh_{ij}$ is the diameter at breast height (in centimeters) of the focal tree at the earlier census; $\beta_{\dbh,j}$ is the amount of the growth rate changed depending on diameter for group $j$;  $\BA_{ijk}$ is the sum of the basal area of all trees of competitor species group $k$; $\lambda_{jk}$ is the change in growth for individuals of group $j$ from nearby competitors of group $k$; and $\epsilon_{ij}$ is a random error term distributed $\text{Normal}(0, \sigma^2)$.-->

We estimate the model's parameters using Bayesian linear regression implemented in the `fit_bayesian_model()` function. TODO: define all parameters

For this linear model's case, there exists a closed form solution as described here. As such, the `fit_bayesian_model()` function using matrix algebra to obtain all parameter estimates, rather than computationally expensive Monte Carlo approximations. The inputs to this function are a `focal_vs_comp` data frame, `prior_param` a list of priors, and a boolean flag `run_shuffle` on whether or not to run competitor-species identity permutations which we will demonstrate below on the Michigan Big Woods data. This function returns the posterior means of all parameters.

Using these posterior means, we then use the posterior predictive distribution to obtain fitted/predicted values $\widehat{y}$ of the dbh for each focal tree using the `predict_bayesian_model()`. These $\widehat{y}$ can then be compared to the observed $y$ dbh's to compute the root mean-square error, a measure of a model's predictive error which has the same units as the observed data $y$.

### Big Woods 

For the Michigan Big Woods data we present two use cases of the model fitting and prediction scheme. The first use case is the simplest where we assess the fit of the model using root mean squared error. The second use case then answers the question of whether species competitor identity matters using permutation test. 

For the first use case, we fit the linear model specified in Equation XXX to our data frame of type `focal_vs_comp`. This input/outputs of the `fit_bayesian_model()` function are lists of the prior/posterior means of parameters of the linear regression specified in XXX. Generally speaking, there are two classes of regression parameters: $\beta$ main effects and $\lambda$ competitive effects. In the upcoming Section \ref{viz-posterior-distributions}, we will present code visualizing this posterior distributions.

```{r bw-model-fit}
posterior_param_bw <- focal_vs_comp_bw %>%
  fit_bayesian_model(prior_param = NULL)
```

This output of posterior parameters for the specified competition model are then used along with the posterior predictive distribution encoded in `predict_bayesian_model()` to return predicted growths for each individual tree. We join these predicted growths to the original growth data frame. 

```{r bw-model-predict}
predictions <- focal_vs_comp_bw %>%
  predict_bayesian_model(posterior_param = posterior_param_bw) %>%
  right_join(bw_growth_df, by = c("focal_ID" = "treeID"))
```

We then use the `rmse()` function from the `yardstick` package to obtain the root mean squared error of the observed versus fitted values of growth. 

```{r bw-model-rmse}
predictions %>%
  yardstick::rmse(truth = growth, estimate = growth_hat) %>%
  pull(.estimate)
```

The second use case is near identical to the first, but with a small change in the code to test whether the identity of the competitor matters. By adding a `run_shuffle = TRUE` argument to `fit_bayesian_model()`, for each focal tree its competitor trees' species identity will be "shuffled" randomly much like in a permutation test. By shuffling these species labels we are effectively fitting the model under a null model that competitor species identity does not matter. If the "shuffled" RMSE's are consistently lower than the unshuffled RMSE corresponding to the observed data, then we have evidence to suggest that competitor identity matters to competitive interactions.

```{r bw-model-shuffle-fit}
posterior_param_bw_shuffle <- focal_vs_comp_bw %>%
  fit_bayesian_model(prior_param = NULL, run_shuffle = TRUE)
```

```{r bw-model-shuffle-predict}
predictions_shuffle <- focal_vs_comp_bw %>%
  predict_bayesian_model(posterior_param = posterior_param_bw_shuffle) %>%
  right_join(bw_growth_df, by = c("focal_ID" = "treeID"))
```

```{r bw-model-shuffle-rmse}
predictions_shuffle %>%
  rmse(truth = growth, estimate = growth_hat) %>%
  pull(.estimate)
```

The RMSE is fact lower for the non-shuffled version, indicative of a better model fit. This gives support for the idea that competitor identity does matter for competitive interactions. In @allen_permutation_2020 we run this shuffle a large number of times to construct a full permutation distribution to show that this difference is robust to resampling variation.

### SCBI 

In the case of the SCBI data, we once again perform the same model fitting and computing of fitted growths as with the Big Woods data, but this time we map the residuals of the observed minus fitted values to look for spatial patterns. 

```{r scbi-model-fit}
posterior_param_scbi <- focal_vs_comp_scbi %>%
  fit_bayesian_model(prior_param = NULL, run_shuffle = FALSE)
```

```{r scbi-model-predict}
scbi_growth_df_noCV <- focal_vs_comp_scbi %>%
  predict_bayesian_model(posterior_param = posterior_param_scbi) %>%
  right_join(scbi_growth_df, by = c("focal_ID" = "stemID"))
```

```{r scbi-model-rmse}
scbi_growth_df_noCV %>%
  rmse(truth = growth, estimate = growth_hat) %>%
  pull(.estimate)
```

In Figures \ref{fig:scbi-model-residuals} and \ref{fig:scbi-model-residuals-2} we present the residuals. 

```{r scbi-model-residuals, out.width="100%", fig.cap="Predicted versus observed growth.", echo = FALSE}
ggplot(scbi_growth_df_noCV, aes(x = growth, y = growth_hat)) +
  geom_point(size = 0.5, color = rgb(0, 0, 0, 0.25)) +
  stat_smooth(method = "lm") +
  geom_abline(slope = 1, intercept = 0) +
  coord_fixed() +
  labs(
    x = "Observed growth in dbh", y = "Predicted growth in dbh",
    title = "Predicted vs Observed Growth"
  )
```

```{r scbi-model-residuals-2, out.width="80%", fig.cap="Spatial distribution of residuals for model applied to SCBI data.", echo = FALSE}
scbi_growth_df_noCV %>%
  st_as_sf() %>%
  # TODO: Need to investigate missingness
  filter(!is.na(growth_hat)) %>%
  mutate(
    error = growth - growth_hat,
    error_bin = cut_number(error, n = 5),
    error_compress = ifelse(error < -0.75, -0.75, ifelse(error > 0.75, 0.75, error))
  ) %>%
  ggplot() +
  geom_sf(aes(col = error_compress), size = 1) +
  theme_bw() +
  scale_color_gradient2(
    low = "#ef8a62", mid = "#f7f7f7", high = "#67a9cf",
    name = expression(paste("Residual (cm ", y^{-1}, ")")),
    breaks = seq(from = -0.75, to = 0.75, by = 0.25),
    labels = c("< -0.75", "-0.5", "0.25", "0", "0.25", "0.5", "> 0.75")
  ) +
  labs(x = "Meter", y = "Meter")
```


## Run spatial cross-validation

The model fits and predictions in Section \ref{model-fit-predict} all suffer from a common failing: they use the same data to both fit the model and to assess the model's performance using the RMSE. As argued by @roberts_cross-validation_2017, this can lead to overly optimistic assessments of model quality as the models can be overfit, in particular in situations where spatial-autocorrelation is present. To mitigate the effects of such overfitting, we use a spatially block cross-validation algorithm implemented in the `run_cv()`. This function at its core uses the same model fitting implemented in the `fit_bayesian_model()` function, however trains the model on $k-1$ spatial folds of the train and returns fitted values for the test data. Recall that the spatial blocking scheme wass encoded in Section \ref{spatial-information}.

### Big Woods

Applying this spatially cross-validated model fit yields an RMSE is higher than that when the model is fit without cross validation. In other words, our model fits in \ref{model-fit-predict} were overly optimistic in the model's fitting power, whereas a cross-validated results yield an estimate that is closer to the truth. See @allen_permutation_2020 for more discussion of this. 

```{r bw-spatial-cv}
cv_bw <- focal_vs_comp_bw %>%
  run_cv(max_dist = max_dist, cv_grid = bw_cv_grid) %>%
  right_join(bw_growth_df, by = c("focal_ID" = "treeID"))

cv_bw %>%
  rmse(truth = growth, estimate = growth_hat) %>%
  pull(.estimate)
```


### SCBI

Observe once again that this RMSE is much higher than that for the above SCBI model fit without cross-validation. 

```{r scbi-spatial-cv}
cv_scbi <- focal_vs_comp_scbi %>%
  run_cv(max_dist = max_dist, cv_grid = scbi_cv_grid) %>%
  right_join(scbi_growth_df, by = c("focal_ID" = "treeID"))

cv_scbi %>%
  rmse(truth = growth, estimate = growth_hat) %>%
  pull(.estimate)
```




## Visualize posterior distributions {#viz-posterior-distributions}

Lastly, we return to the model fits from Section \ref{model-fit-predict} and present tools to visually explore the posterior distributions of all parameters in our model. There are two main groups of parameters to consider. The $\beta$ coefficients tell us about how fast each species grows and how this depends on DBH while the full matrix of $\lambda$ values describe the competitive effects between pairs of species. There is a rich literature on this matrix (cite). 

DO WE NEED TO DESCRIBE MECHANICS? Because of the structure of the `bw_fit_model` object we cannot simply draw these curves based on the posterior distribution. `bw_fit_model()` gives the parameters *compared* to a baseline. This is not of direct interest. So to display these parameters, as we care about them, we have to sample from the baseline distribution and from the comparison one to get the posterior distribution of interest. 


### Big Woods 

Here we re-run the model fit to the Big Woods data from Section \ref{model-fit-predict}, but this time use "family" as the group for comparison which has. This makes the posterior distributions easier to follow. Also, surprisingly, grouping by family performed just as well as grouping by species @allen_permutation_2020. First we re-run `create_focal_vs_comp()` and `fit_bayesian_model()` with no permutation shuffling with the grouping variable as family.

```{r bw-posterior-viz-0}
focal_vs_comp_bw <- bw_growth_df %>%
  mutate(sp = family) %>%
  create_focal_vs_comp(max_dist = max_dist, cv_grid_sf = bw_cv_grid, 
                       id = "treeID")

posterior_param_bw <- focal_vs_comp_bw %>%
  fit_bayesian_model(prior_param = NULL, run_shuffle = FALSE)
```

Now the posterior parameter outputs of `fit_bayesian_model()` are passed to `plot_bayesian_model_parameters()` to generate visualizations of the posterior parameters. These visualizations are displayed in Figure 5 of @allen_permutation_2020. For simplicity we only plot a subset of the species families. 

```{r bw-posterior-viz-1}
posterior_plots_bw <- plot_bayesian_model_parameters(
  posterior_param = posterior_param_bw,
  sp_to_plot = c("cornaceae", "fagaceae", "hamamelidaceae", "juglandaceae", 
                 "lauraceae", "rosaceae", "sapindaceae", "ulmaceae")
)
```

The output is a list with three plots stored. Figure \ref{fig:bw-posterior-viz-beta0} The element `beta_0` gives the baseline growth intercept $\beta_0$, i.e., how fast an individual of each group grows independent of DBH).

```{r bw-posterior-viz-beta0, out.width="100%", fig.cap="Posterior distribution of beta0."}
posterior_plots_bw[["beta_0"]]
```

Figure \ref{fig:bw-posterior-viz-beta-dbh} Next `beta_dbh` gives the slope for DBH slope $\beta_{dbh,i}$ for each group.

```{r bw-posterior-viz-beta-dbh, out.width="100%", fig.cap="Posterior distribution of betadbh."}
posterior_plots_bw[["beta_dbh"]]
```

Finally Figure \ref{fig:bw-posterior-viz-lambda} `lambda` gives the competition coefficients $\lambda$.

```{r bw-posterior-viz-lambda, out.width="100%", fig.cap="Posterior distribution of lambda's for Big Woods."}
posterior_plots_bw[["lambda"]]
```


### SCBI

We revisit the posterior parameters for the SCBI from Section {model-fit-predict}, but this time only focus on the $\lambda$ competition coefficients. 

```{r scbi-posterior-viz-1}
posterior_plots_scbi <- plot_bayesian_model_parameters(
  posterior_param = posterior_param_scbi,
  sp_to_plot = c("quru", "litu", "cagl", "cato")
)
```

```{r scbi-posterior-viz-lambda, out.width="100%", fig.cap="Posterior distribution of lambda's for SCBI."}
posterior_plots_scbi[["lambda"]]
```

Add explanation here. 

HEY BERT PICK IT UP HERE



# Discussion





# Acknowledgments





# References




